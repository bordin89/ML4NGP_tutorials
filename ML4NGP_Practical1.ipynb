{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bordin89/ML4NGP_tutorials/blob/main/ML4NGP_Practical1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n--pDIYdqGeU",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#@title Colab Setup: Install TED tools, dependencies & Foldseek\n",
        "\n",
        "import os, pathlib\n",
        "\n",
        "# === 1. Setup workspace ======================================================\n",
        "BASE_DIR = pathlib.Path(\"/content\").resolve()\n",
        "WORK_DIR = BASE_DIR / \"ted_workshop\"\n",
        "WORK_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"Working directory: {WORK_DIR}\")\n",
        "os.chdir(WORK_DIR)\n",
        "\n",
        "# === 2. Install Python dependencies ========\n",
        "print(\"Installing Python dependencies...\")\n",
        "\n",
        "!pip install -q \\\n",
        "    einops==0.6.1 \\\n",
        "    natsort==8.3.1 \\\n",
        "    pydantic==1.10.8 \\\n",
        "    pandas biopython tqdm requests py3Dmol rotary-embedding-torch pdb-tools\n",
        "\n",
        "!pip install ipywidgets\n",
        "!jupyter nbextension enable --py widgetsnbextension\n",
        "\n",
        "\n",
        "# === 3. Clone TED tools repository ===========================================\n",
        "if not (WORK_DIR / \"ted-tools\").exists():\n",
        "    print(\"Cloning TED tools repository...\")\n",
        "    !git clone https://github.com/psipred/ted-tools.git\n",
        "else:\n",
        "    print(\"TED tools repository already present\")\n",
        "\n",
        "# === 4. Install Foldseek =========================\n",
        "print(\"Installing Foldseek...\")\n",
        "\n",
        "!rm -rf foldseek foldseek.tar.gz\n",
        "\n",
        "!wget -q https://mmseqs.com/foldseek/foldseek-linux-avx2.tar.gz -O foldseek.tar.gz\n",
        "!mkdir -p foldseek\n",
        "!tar xzf foldseek.tar.gz -C foldseek --strip-components=1\n",
        "!rm foldseek.tar.gz\n",
        "\n",
        "FOLDSEEK_BIN = WORK_DIR / \"foldseek\" / \"bin\" / \"foldseek\"\n",
        "os.environ[\"PATH\"] = f\"{WORK_DIR}/foldseek/bin:\" + os.environ[\"PATH\"]\n",
        "\n",
        "print(\"Foldseek binary:\", FOLDSEEK_BIN)\n",
        "!ls -R foldseek\n",
        "\n",
        "print(\"\\nFoldseek version check:\")\n",
        "!{FOLDSEEK_BIN} version\n",
        "\n",
        "# === 5. Create structure and results directories =============================\n",
        "STRUCTURE_DIR   = WORK_DIR / \"structures\"\n",
        "TED_INPUT_DIR   = WORK_DIR / \"ted_input\"\n",
        "TED_RESULTS_DIR = WORK_DIR / \"ted_results\"\n",
        "\n",
        "for d in [STRUCTURE_DIR, TED_INPUT_DIR, TED_RESULTS_DIR]:\n",
        "    d.mkdir(exist_ok=True)\n",
        "\n",
        "print(\"\\nDirectory Setup Complete:\")\n",
        "print(f\"  Structures:  {STRUCTURE_DIR}\")\n",
        "print(f\"  TED Input:   {TED_INPUT_DIR}\")\n",
        "print(f\"  TED Results: {TED_RESULTS_DIR}\")\n",
        "print(f\"  Foldseek:    {FOLDSEEK_BIN}\")\n",
        "\n",
        "print(\"\\nSetup complete! Ready for structure downloads.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download 10 example structures (AFDB v6) into TED_INPUT_DIR\n",
        "\n",
        "import os\n",
        "import pathlib\n",
        "import requests\n",
        "from shutil import copy2\n",
        "\n",
        "# Workspace paths (same as setup cell)\n",
        "BASE_DIR      = pathlib.Path(\"/content\").resolve()\n",
        "WORK_DIR      = BASE_DIR / \"ted_workshop\"\n",
        "STRUCTURE_DIR = WORK_DIR / \"structures\"\n",
        "TED_INPUT_DIR = WORK_DIR / \"ted_input\"\n",
        "\n",
        "PDB_DIR  = STRUCTURE_DIR / \"pdb\"\n",
        "AFDB_DIR = STRUCTURE_DIR / \"afdb\"\n",
        "PDB_DIR.mkdir(parents=True, exist_ok=True)\n",
        "AFDB_DIR.mkdir(parents=True, exist_ok=True)\n",
        "TED_INPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"PDB directory:  {PDB_DIR}\")\n",
        "print(f\"AFDB directory: {AFDB_DIR}\")\n",
        "print(f\"TED input:      {TED_INPUT_DIR}\\n\")\n",
        "\n",
        "# --- Example IDs ---------------------\n",
        "\n",
        "af_uniprot_ids = [\n",
        "    \"P04637\",  # p53\n",
        "    \"P68871\",  # Hemoglobin beta\n",
        "    \"P69905\",  # Hemoglobin alpha\n",
        "    \"P38398\",  # BRCA1\n",
        "    \"P0CG47\",  # Ubiquitin-40S ribosomal protein S27a\n",
        "    \"P00533\",  # EGFR\n",
        "    \"P01009\",  # Alpha-1-antitrypsin\n",
        "    \"P05067\",  # APP\n",
        "    \"P01112\",  # HRAS\n",
        "    \"P02649\",  # APOE\n",
        "]\n",
        "\n",
        "def download_pdb(pdb_id: str, out_dir: pathlib.Path) -> pathlib.Path:\n",
        "    url = f\"https://files.rcsb.org/download/{pdb_id}.pdb\"\n",
        "    out_path = out_dir / f\"{pdb_id}.pdb\"\n",
        "    if out_path.exists():\n",
        "        print(f\"{pdb_id}: already exists\")\n",
        "        return out_path\n",
        "    print(f\"Downloading PDB {pdb_id} ...\")\n",
        "    r = requests.get(url)\n",
        "    r.raise_for_status()\n",
        "    out_path.write_bytes(r.content)\n",
        "    print(f\"   ↳ saved to {out_path}\")\n",
        "    return out_path\n",
        "\n",
        "def download_afdb(uniprot_id: str, out_dir: pathlib.Path) -> pathlib.Path:\n",
        "    url = f\"https://alphafold.ebi.ac.uk/files/AF-{uniprot_id}-F1-model_v6.pdb\"\n",
        "    out_path = out_dir / f\"AF-{uniprot_id}-F1-model_v6.pdb\"\n",
        "    if out_path.exists():\n",
        "        print(f\"AFDB {uniprot_id}: already exists\")\n",
        "        return out_path\n",
        "    print(f\"Downloading AFDB v6 {uniprot_id} ...\")\n",
        "    r = requests.get(url)\n",
        "    r.raise_for_status()\n",
        "    out_path.write_bytes(r.content)\n",
        "    print(f\"   ↳ saved to {out_path}\")\n",
        "    return out_path\n",
        "\n",
        "# --- Download all structures -------------------------------------------------\n",
        "afdb_files = [download_afdb(uid, AFDB_DIR) for uid in af_uniprot_ids]\n",
        "\n",
        "print(\"\\nCopying all structures into TED_INPUT_DIR ...\")\n",
        "for f in afdb_files:\n",
        "    dest = TED_INPUT_DIR / f.name\n",
        "    if not dest.exists():\n",
        "        copy2(f, dest)\n",
        "        print(f\"   ↳ {f.name} -> {dest}\")\n",
        "    else:\n",
        "        print(f\"   ↳ {f.name} already present in TED_INPUT_DIR\")\n",
        "\n",
        "print(\"\\nDone! Contents of TED_INPUT_DIR:\")\n",
        "!ls -1 \"{TED_INPUT_DIR}\""
      ],
      "metadata": {
        "id": "BnTFqZkn7DWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title TED consensus setup (Merizo, UniDoc, Chainsaw, STRIDE, patch run_segmentation.sh)\n",
        "\n",
        "import os, pathlib\n",
        "\n",
        "BASE_DIR     = pathlib.Path(\"/content\").resolve()\n",
        "WORK_DIR     = BASE_DIR / \"ted_workshop\"\n",
        "TED_CONS_DIR = WORK_DIR / \"ted-tools\" / \"ted_consensus_1.0\"\n",
        "PROGRAMS_DIR = TED_CONS_DIR / \"programs\"\n",
        "MERIZO_DIR   = PROGRAMS_DIR / \"merizo\"\n",
        "MERIZO_W_DIR = MERIZO_DIR / \"weights\"\n",
        "UNIDOC_DIR   = PROGRAMS_DIR / \"unidoc\"\n",
        "CHAINSAW_DIR = PROGRAMS_DIR / \"chainsaw\"\n",
        "RUN_SCRIPT   = TED_CONS_DIR / \"run_segmentation.sh\"\n",
        "\n",
        "os.chdir(TED_CONS_DIR)\n",
        "print(\"TED consensus dir:\", TED_CONS_DIR)\n",
        "\n",
        "PROGRAMS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# --- Merizo weights -------------------------------\n",
        "BASE_URL = \"https://github.com/psipred/Merizo/raw/main/weights\"\n",
        "WEIGHTS_FILES = [\"weights_part_0.pt\", \"weights_part_1.pt\", \"weights_part_2.pt\"]\n",
        "\n",
        "MERIZO_W_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"\\nChecking Merizo weights in\", MERIZO_W_DIR)\n",
        "for fname in WEIGHTS_FILES:\n",
        "    out_path = MERIZO_W_DIR / fname\n",
        "    if out_path.exists():\n",
        "        print(f\"   ✔ {fname} already present\")\n",
        "        continue\n",
        "    url = f\"{BASE_URL}/{fname}\"\n",
        "    print(f\"   Downloading {fname} ...\")\n",
        "    !wget -q \"{url}\" -O \"{out_path}\"\n",
        "print(\"Merizo weights ready.\\n\")\n",
        "\n",
        "# --- UniDoc) ----------------------\n",
        "UNIDOC_URL = \"https://yanglab.qd.sdu.edu.cn/UniDoc/download/UniDoc_20250514.tgz\"\n",
        "UNIDOC_TGZ = PROGRAMS_DIR / \"UniDoc_20250514.tgz\"\n",
        "\n",
        "if UNIDOC_DIR.exists():\n",
        "    print(\"UniDoc already installed at\", UNIDOC_DIR, \"\\n\")\n",
        "else:\n",
        "    print(\"Downloading UniDoc from updated URL ...\")\n",
        "    !wget -q --no-check-certificate \"{UNIDOC_URL}\" -O \"{UNIDOC_TGZ}\"\n",
        "\n",
        "    print(\"Extracting UniDoc ...\")\n",
        "    !tar -xzf \"{UNIDOC_TGZ}\" -C \"{PROGRAMS_DIR}\"\n",
        "    !rm \"{UNIDOC_TGZ}\"\n",
        "\n",
        "    unpacked_dir = PROGRAMS_DIR / \"UniDoc\"\n",
        "    if unpacked_dir.exists():\n",
        "        unpacked_dir.rename(UNIDOC_DIR)\n",
        "        print(\"UniDoc unpacked to\", UNIDOC_DIR)\n",
        "    else:\n",
        "        raise SystemExit(\"UniDoc folder not found after extraction.\")\n",
        "\n",
        "    helper_script = TED_CONS_DIR / \"scripts\" / \"Run_UniDoc_from_scratch_structure_afdb.py\"\n",
        "    if helper_script.exists():\n",
        "        !cp \"{helper_script}\" \"{UNIDOC_DIR}/\"\n",
        "        print(\"Copied Run_UniDoc_from_scratch_structure_afdb.py into UniDoc dir\\n\")\n",
        "    else:\n",
        "        print(\"Helper script not found at\", helper_script, \"\\n\")\n",
        "\n",
        "# --- Refresh Chainsaw from upstream repo ---------------------------------\n",
        "print(\"Ensuring latest Chainsaw...\")\n",
        "if CHAINSAW_DIR.exists():\n",
        "    !rm -rf \"{CHAINSAW_DIR}\"\n",
        "\n",
        "!git clone -q https://github.com/JudeWells/chainsaw.git \"{CHAINSAW_DIR}\"\n",
        "print(\"Chainsaw cloned into\", CHAINSAW_DIR, \"\\n\")\n",
        "\n",
        "# --- Ensure STRIDE is built in programs/chainsaw/stride ------------------\n",
        "STRIDE_DIR = CHAINSAW_DIR / \"stride\"\n",
        "STRIDE_BIN = STRIDE_DIR / \"stride\"\n",
        "STRIDE_TAR_GZ = STRIDE_DIR / \"stride.tar.gz\"\n",
        "STRIDE_TGZ = STRIDE_DIR / \"stride.tgz\"\n",
        "\n",
        "print(\"Checking STRIDE binary in\", STRIDE_DIR)\n",
        "\n",
        "if STRIDE_BIN.exists():\n",
        "    print(\"STRIDE binary already present:\", STRIDE_BIN)\n",
        "else:\n",
        "    # Make sure we have build tools\n",
        "    print(\"STRIDE binary missing; preparing to build from tarball...\")\n",
        "    !command -v make >/dev/null 2>&1 || (apt-get update -qq && apt-get install -y -qq build-essential >/dev/null)\n",
        "\n",
        "    os.chdir(STRIDE_DIR)\n",
        "\n",
        "    if STRIDE_TAR_GZ.exists():\n",
        "        print(\"Extracting stride.tar.gz ...\")\n",
        "        !tar -xzf \"stride.tar.gz\"\n",
        "    elif STRIDE_TGZ.exists():\n",
        "        print(\"Extracting stride.tgz ...\")\n",
        "        !tar -xzf \"stride.tgz\"\n",
        "    else:\n",
        "        raise SystemExit(\" No stride.tar.gz or stride.tgz found in stride directory.\")\n",
        "\n",
        "    print(\" Running make to build STRIDE...\")\n",
        "    !make\n",
        "    !chmod +x \"stride\"\n",
        "\n",
        "    os.chdir(TED_CONS_DIR)\n",
        "\n",
        "    if STRIDE_BIN.exists():\n",
        "        print(\"STRIDE binary built at\", STRIDE_BIN, \"\\n\")\n",
        "    else:\n",
        "        raise SystemExit(\"STRIDE build did not produce 'stride' binary.\")\n",
        "\n",
        "# --- 5️⃣ Patch run_segmentation.sh: remove venv block cleanly ----------------\n",
        "print(\"Patching run_segmentation.sh to remove virtualenv requirement...\")\n",
        "\n",
        "if not RUN_SCRIPT.exists():\n",
        "    raise SystemExit(f\"Cannot find {RUN_SCRIPT}\")\n",
        "\n",
        "lines = RUN_SCRIPT.read_text().splitlines()\n",
        "new_lines = []\n",
        "in_venv_block = False\n",
        "venv_removed = False\n",
        "\n",
        "for line in lines:\n",
        "    stripped = line.strip()\n",
        "\n",
        "    if 'VENV_DIR=\"ted_consensus\"' in line:\n",
        "        in_venv_block = True\n",
        "        venv_removed = True\n",
        "        new_lines.append(\n",
        "            '# [Colab] Using global Python environment instead of \"ted_consensus\" virtualenv.'\n",
        "        )\n",
        "        continue\n",
        "\n",
        "    if in_venv_block:\n",
        "        if stripped == \"fi\":\n",
        "            in_venv_block = False\n",
        "        continue\n",
        "\n",
        "    new_lines.append(line)\n",
        "\n",
        "RUN_SCRIPT.write_text(\"\\n\".join(new_lines))\n",
        "os.chmod(RUN_SCRIPT, 0o755)\n",
        "\n",
        "if venv_removed:\n",
        "    print(\"Virtualenv block removed from run_segmentation.sh\")\n",
        "else:\n",
        "    print(\"No virtualenv block found (already removed)\")"
      ],
      "metadata": {
        "id": "j0d25ebT9W8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run TED consensus on TED_INPUT_DIR\n",
        "\n",
        "import os, pathlib\n",
        "\n",
        "BASE_DIR        = pathlib.Path(\"/content\").resolve()\n",
        "WORK_DIR        = BASE_DIR / \"ted_workshop\"\n",
        "TED_CONS_DIR    = WORK_DIR / \"ted-tools\" / \"ted_consensus_1.0\"\n",
        "TED_INPUT_DIR   = WORK_DIR / \"ted_input\"\n",
        "TED_RESULTS_DIR = WORK_DIR / \"ted_results\"\n",
        "\n",
        "os.chdir(TED_CONS_DIR)\n",
        "\n",
        "# Path for the Colab-specific wrapper script\n",
        "COLAB_RUN = TED_CONS_DIR / \"run_segmentation_colab.sh\"\n",
        "\n",
        "script_content = r\"\"\"#!/bin/bash\n",
        "\n",
        "# This file is a part of TED: The Encyclopedia of Domains. If you utilize or reference any content from this file,\n",
        "# please cite the following paper:\n",
        "# Lau et al., 2024. Exploring structural diversity across the protein universe with The Encyclopedia of Domains.\n",
        "\n",
        "# Function to display usage message\n",
        "usage() {\n",
        "    echo \"Usage: $0 -i <input_directory_with_pdb_files> -o <output_directory>\"\n",
        "    exit 1\n",
        "}\n",
        "\n",
        "# [Colab] Using global Python environment instead of 'ted_consensus' virtualenv.\n",
        "\n",
        "# Parse command-line arguments\n",
        "while getopts \"i:o:\" opt; do\n",
        "    case $opt in\n",
        "        i) INPUT_DIR=\"$OPTARG\" ;;\n",
        "        o) OUTPUT_DIR=\"$OPTARG\" ;;\n",
        "        *) usage ;;\n",
        "    esac\n",
        "done\n",
        "\n",
        "# Check if both input and output directories are provided\n",
        "if [ -z \"$INPUT_DIR\" ] || [ -z \"$OUTPUT_DIR\" ]; then\n",
        "    usage\n",
        "fi\n",
        "\n",
        "# Check if the input directory exists\n",
        "if [ ! -d \"$INPUT_DIR\" ]; then\n",
        "    echo \"Error: $INPUT_DIR is not a directory\"\n",
        "    exit 1\n",
        "fi\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "if [ ! -d \"$OUTPUT_DIR\" ]; then\n",
        "    mkdir -p \"$OUTPUT_DIR\"\n",
        "fi\n",
        "\n",
        "SCRIPT_DIR=$( cd -- \"$( dirname -- \"${BASH_SOURCE[0]}\" )\" &> /dev/null && pwd )\n",
        "PY=$(which python)\n",
        "\n",
        "SEGMENT=\"${SCRIPT_DIR}/scripts/segment.sh\"\n",
        "CONSENSUS=\"${SCRIPT_DIR}/scripts/get_consensus.py\"\n",
        "FILTER_DOMAINS=\"${SCRIPT_DIR}/scripts/filter_domains_consensus.py\"\n",
        "\n",
        "# Run Merizo on the input directory\n",
        "out_merizo=\"${OUTPUT_DIR}/chopping_merizo.txt\"\n",
        "log_merizo=\"${OUTPUT_DIR}/chopping_merizo.log\"\n",
        "bash \"${SEGMENT}\" -i \"${INPUT_DIR}\" -m merizo -o \"${OUTPUT_DIR}\" > \"${log_merizo}\" 2>&1\n",
        "\n",
        "if test ! -f \"${out_merizo}\" || test ! -s \"${out_merizo}\"; then\n",
        "    echo \"Expected to find chopping file for Merizo at ${out_merizo}!\"\n",
        "    exit 1\n",
        "fi\n",
        "\n",
        "# Run UniDoc on the Merizo output\n",
        "out_unidoc=\"${OUTPUT_DIR}/chopping_unidoc.txt\"\n",
        "log_unidoc=\"${OUTPUT_DIR}/chopping_unidoc.log\"\n",
        "bash \"${SEGMENT}\" -i \"${INPUT_DIR}\" -m unidoc -o \"${OUTPUT_DIR}\" -c \"${out_merizo}\" > \"${log_unidoc}\" 2>&1\n",
        "\n",
        "if test ! -f \"${out_unidoc}\" || test ! -s \"${out_unidoc}\"; then\n",
        "    echo \"Expected to find chopping file for UniDoc at ${out_unidoc}!\"\n",
        "    exit 1\n",
        "fi\n",
        "\n",
        "# Run Chainsaw on the input directory\n",
        "out_chainsaw=\"${OUTPUT_DIR}/chopping_chainsaw.txt\"\n",
        "log_chainsaw=\"${OUTPUT_DIR}/chopping_chainsaw.log\"\n",
        "bash \"${SEGMENT}\" -i \"${INPUT_DIR}\" -m chainsaw -o \"${OUTPUT_DIR}\" > \"${log_chainsaw}\" 2>&1\n",
        "\n",
        "if test ! -f \"${out_chainsaw}\" || test ! -s \"${out_chainsaw}\"; then\n",
        "    echo \"Expected to find chopping file for Chainsaw at ${out_chainsaw}!\"\n",
        "    exit 1\n",
        "fi\n",
        "\n",
        "echo \"Calculating consensus domains from Merizo, UniDoc and Chainsaw outputs.. \"\n",
        "\n",
        "# Calculate consensus from each of the outputs\n",
        "out_consensus=\"${OUTPUT_DIR}/consensus.tsv\"\n",
        "log_consensus=\"${OUTPUT_DIR}/consensus.log\"\n",
        "\"${PY}\" \"${CONSENSUS}\" -c \"${out_merizo}\" \"${out_chainsaw}\" \"${out_unidoc}\" -o \"${out_consensus}\" > \"${log_consensus}\" 2>&1\n",
        "\n",
        "if test -f \"${out_consensus}\"; then\n",
        "    \"${PY}\" \"${FILTER_DOMAINS}\" \"${out_consensus}\" -o \"${out_consensus}.tmp\"\n",
        "\n",
        "    if [ $? == 0 ]; then\n",
        "        mv \"${out_consensus}.tmp\" \"${out_consensus}\"\n",
        "    fi\n",
        "else\n",
        "    echo \"Expected to find consensus domain file at ${out_consensus}\"\n",
        "    exit 1\n",
        "fi\n",
        "\n",
        "echo \"Consensus domain file saved at ${out_consensus}\"\n",
        "\"\"\"\n",
        "\n",
        "# Write Colab-specific script\n",
        "COLAB_RUN.write_text(script_content)\n",
        "os.chmod(COLAB_RUN, 0o755)\n",
        "\n",
        "print(\"Environment:\", COLAB_RUN)\n",
        "print(\"Input dir:   \", TED_INPUT_DIR)\n",
        "print(\"Output dir:  \", TED_RESULTS_DIR, \"\\n\")\n",
        "\n",
        "cmd = f\"bash '{COLAB_RUN}' -i '{TED_INPUT_DIR}' -o '{TED_RESULTS_DIR}'\"\n",
        "print(\"Running TED consensus...\\n\")\n",
        "print(cmd, \"\\n\")\n",
        "\n",
        "!bash -lc \"{cmd}\"\n",
        "\n",
        "print(\"\\nFiles in TED_RESULTS_DIR:\")\n",
        "!ls -1 \"{TED_RESULTS_DIR}\""
      ],
      "metadata": {
        "id": "UNWCrpHQEv6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/ted_workshop/ted_results/chopping_chainsaw.txt"
      ],
      "metadata": {
        "id": "vV_0xMTGLgsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Explore TED AFDB domains\n",
        "\n",
        "import os, pathlib\n",
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "import py3Dmol\n",
        "from IPython.display import display\n",
        "\n",
        "BASE_DIR        = pathlib.Path(\"/content\").resolve()\n",
        "WORK_DIR        = BASE_DIR / \"ted_workshop\"\n",
        "TED_INPUT_DIR   = WORK_DIR / \"ted_input\"\n",
        "TED_RESULTS_DIR = WORK_DIR / \"ted_results\"\n",
        "\n",
        "consensus_path  = TED_RESULTS_DIR / \"consensus.tsv\"\n",
        "merizo_path     = TED_RESULTS_DIR / \"chopping_merizo.txt\"\n",
        "unidoc_path     = TED_RESULTS_DIR / \"chopping_unidoc.txt\"\n",
        "chainsaw_path   = TED_RESULTS_DIR / \"chopping_chainsaw.txt\"\n",
        "\n",
        "# --- Load consensus -------------------------------------------------------\n",
        "if not consensus_path.exists():\n",
        "    raise FileNotFoundError(f\"Cannot find consensus.tsv at {consensus_path}\")\n",
        "\n",
        "cons_cols = [\n",
        "    \"target_id\", \"md5\", \"nres\", \"n_high\", \"n_med\", \"n_low\",\n",
        "    \"high_domains\", \"med_domains\", \"low_domains\",\n",
        "]\n",
        "cons_df = pd.read_csv(consensus_path, sep=\"\\t\", header=None, names=cons_cols)\n",
        "\n",
        "# AFDB-only\n",
        "cons_df = cons_df[cons_df[\"target_id\"].str.startswith(\"AF-\")].reset_index(drop=True)\n",
        "if cons_df.empty:\n",
        "    raise RuntimeError(\"consensus.tsv has no AF-* entries; rerun TED on AFDB-only inputs.\")\n",
        "\n",
        "# --- chopping helpers -----------------------------------------------------\n",
        "def load_chopping(path):\n",
        "    \"\"\"\n",
        "    chopping_* format (simplified):\n",
        "\n",
        "      target_id  ...  domain_string  score\n",
        "\n",
        "    domain_string is the SECOND-TO-LAST column.\n",
        "    \"\"\"\n",
        "    if not path.exists():\n",
        "        return {}\n",
        "    mapping = {}\n",
        "    with open(path) as fh:\n",
        "        for line in fh:\n",
        "            line = line.rstrip(\"\\n\")\n",
        "            if not line or line.startswith(\"#\"):\n",
        "                continue\n",
        "            parts = line.split(\"\\t\")\n",
        "            if len(parts) < 3:\n",
        "                continue\n",
        "            target_id = parts[0]\n",
        "            dom_str   = parts[-2]\n",
        "            mapping[target_id] = dom_str\n",
        "    return mapping\n",
        "\n",
        "merizo_chop   = load_chopping(merizo_path)\n",
        "unidoc_chop   = load_chopping(unidoc_path)\n",
        "chainsaw_chop = load_chopping(chainsaw_path)\n",
        "\n",
        "def parse_domain_string(dom_str):\n",
        "    \"\"\"\n",
        "    Return a list of domains; each domain is a list of (start, end) segments.\n",
        "\n",
        "    Example:\n",
        "      '249-353_596-636,700-800'\n",
        "      -> [ [(249,353),(596,636)], [(700,800)] ]\n",
        "    \"\"\"\n",
        "    domains = []\n",
        "    if not dom_str or dom_str == \"na\":\n",
        "        return domains\n",
        "\n",
        "    for dom in dom_str.split(\",\"):\n",
        "        segs = []\n",
        "        for seg in dom.split(\"_\"):\n",
        "            if \"-\" not in seg:\n",
        "                continue\n",
        "            a, b = seg.split(\"-\")\n",
        "            try:\n",
        "                start, end = int(a), int(b)\n",
        "                segs.append((start, end))\n",
        "            except ValueError:\n",
        "                continue\n",
        "        if segs:\n",
        "            domains.append(segs)\n",
        "    return domains\n",
        "\n",
        "def extract_uniprot_from_afid(target_id: str):\n",
        "    # AF-P00533-F1-model_v6 -> P00533\n",
        "    try:\n",
        "        return target_id.split(\"-\")[1]\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def get_domain_string(target_id, source, row):\n",
        "    if source == \"consensus_high\":\n",
        "        return row[\"high_domains\"], \"Consensus HIGH\"\n",
        "    elif source == \"consensus_med\":\n",
        "        return row[\"med_domains\"], \"Consensus MEDIUM\"\n",
        "    elif source == \"consensus_low\":\n",
        "        return row[\"low_domains\"], \"Consensus LOW\"\n",
        "    elif source == \"merizo\":\n",
        "        return merizo_chop.get(target_id, \"na\"), \"Merizo\"\n",
        "    elif source == \"unidoc\":\n",
        "        return unidoc_chop.get(target_id, \"na\"), \"UniDoc\"\n",
        "    elif source == \"chainsaw\":\n",
        "        return chainsaw_chop.get(target_id, \"na\"), \"Chainsaw\"\n",
        "    else:\n",
        "        return \"na\", source\n",
        "\n",
        "DOMAIN_COLORS = [\n",
        "    \"red\", \"orange\", \"yellow\", \"green\",\n",
        "    \"cyan\", \"blue\", \"magenta\", \"salmon\",\n",
        "    \"lime\", \"violet\", \"gold\", \"deepskyblue\",\n",
        "]\n",
        "\n",
        "# --- Widgets --------------------------------------------------------------\n",
        "\n",
        "target_dropdown = widgets.Dropdown(\n",
        "    options=sorted(cons_df[\"target_id\"].tolist()),\n",
        "    description=\"AF target:\",\n",
        "    layout=widgets.Layout(width=\"70%\"),\n",
        ")\n",
        "\n",
        "source_dropdown = widgets.Dropdown(\n",
        "    options=[\n",
        "        (\"Consensus (high)\", \"consensus_high\"),\n",
        "        (\"Consensus (medium)\", \"consensus_med\"),\n",
        "        (\"Consensus (low)\", \"consensus_low\"),\n",
        "        (\"Merizo\", \"merizo\"),\n",
        "        (\"UniDoc\", \"unidoc\"),\n",
        "        (\"Chainsaw\", \"chainsaw\"),\n",
        "    ],\n",
        "    value=\"consensus_high\",\n",
        "    description=\"Domains:\",\n",
        "    layout=widgets.Layout(width=\"70%\"),\n",
        ")\n",
        "\n",
        "ui  = widgets.VBox([target_dropdown, source_dropdown])\n",
        "out = widgets.Output()\n",
        "\n",
        "def update_view(change=None):\n",
        "    out.clear_output(wait=True)\n",
        "    with out:\n",
        "        target_id = target_dropdown.value\n",
        "        source    = source_dropdown.value\n",
        "\n",
        "        row = cons_df[cons_df[\"target_id\"] == target_id].iloc[0]\n",
        "        dom_str, label = get_domain_string(target_id, source, row)\n",
        "        domains = parse_domain_string(dom_str)\n",
        "        uni_id = extract_uniprot_from_afid(target_id)\n",
        "\n",
        "        pdb_path = TED_INPUT_DIR / f\"{target_id}.pdb\"\n",
        "        if not pdb_path.exists():\n",
        "            print(f\"PDB file not found: {pdb_path}\")\n",
        "            return\n",
        "\n",
        "        with open(pdb_path) as fh:\n",
        "            pdb_str = fh.read()\n",
        "\n",
        "        print(f\"Target: {target_id}\")\n",
        "        if uni_id:\n",
        "            print(f\"   UniProt: {uni_id} (https://alphafold.ebi.ac.uk/entry/{uni_id})\")\n",
        "        print(f\"   Segmentation: {label}\")\n",
        "        print(f\"   Domain string: {dom_str}\")\n",
        "\n",
        "        if domains:\n",
        "            print(\"   Domains (discontinuous segments grouped):\")\n",
        "            for i, segs in enumerate(domains, 1):\n",
        "                seg_str = \"_\".join(f\"{s}-{e}\" for s, e in segs)\n",
        "                print(f\"     D{i}: {seg_str}\")\n",
        "        else:\n",
        "            print(\"   Domains: (none for this method)\")\n",
        "\n",
        "        # --- 3D view ---------------------------------------------------------\n",
        "        view = py3Dmol.view(width=640, height=480)\n",
        "        view.addModel(pdb_str, \"pdb\")\n",
        "        view.setStyle({\"cartoon\": {\"color\": \"lightgrey\"}})\n",
        "\n",
        "\n",
        "        for i, segs in enumerate(domains):\n",
        "            color = DOMAIN_COLORS[i % len(DOMAIN_COLORS)]\n",
        "            for start, end in segs:\n",
        "                sel = {\"resi\": list(range(start, end + 1))}\n",
        "                view.addStyle(sel, {\"cartoon\": {\"color\": color}})\n",
        "\n",
        "        view.zoomTo()\n",
        "        view.show()\n",
        "\n",
        "target_dropdown.observe(update_view, names=\"value\")\n",
        "source_dropdown.observe(update_view, names=\"value\")\n",
        "\n",
        "display(ui, out)\n",
        "update_view()"
      ],
      "metadata": {
        "id": "TjVoubP5WlkO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOq4tUR7l6Q0FtC5Ei5zSd4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}