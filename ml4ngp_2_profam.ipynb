{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMFxHpGexIuCQjcvR4dz3Wb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ceb076075177442eb3571da4719d4856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "A0A140D2T1_ZIKV_Sourisseau_2019.csv",
              "A0A192B1T2_9HIV1_Haddox_2018.csv",
              "A0A1I9GEU1_NEIME_Kennouche_2019.csv",
              "A0A247D711_LISMN_Stadelmann_2021.csv",
              "A0A2Z5U3Z0_9INFA_Doud_2016.csv",
              "A0A2Z5U3Z0_9INFA_Wu_2014.csv",
              "A4D664_9INFA_Soh_2019.csv",
              "A4GRB6_PSEAI_Chen_2020.csv",
              "A4_HUMAN_Seuma_2022.csv",
              "AACC1_PSEAI_Dandage_2018.csv",
              "ACE2_HUMAN_Chan_2020.csv",
              "ADRB2_HUMAN_Jones_2020.csv",
              "AICDA_HUMAN_Gajula_2014_3cycles.csv",
              "AMFR_HUMAN_Tsuboyama_2023_4G3O.csv",
              "AMIE_PSEAE_Wrenbeck_2017.csv",
              "ANCSZ_Hobbs_2022.csv",
              "ARGR_ECOLI_Tsuboyama_2023_1AOY.csv",
              "B2L11_HUMAN_Dutta_2010_binding-Mcl-1.csv",
              "BBC1_YEAST_Tsuboyama_2023_1TG0.csv",
              "BCHB_CHLTE_Tsuboyama_2023_2KRU.csv",
              "BLAT_ECOLX_Deng_2012.csv",
              "BLAT_ECOLX_Firnberg_2014.csv",
              "BLAT_ECOLX_Jacquier_2013.csv",
              "BLAT_ECOLX_Stiffler_2015.csv",
              "BRCA1_HUMAN_Findlay_2018.csv",
              "BRCA2_HUMAN_Erwood_2022_HEK293T.csv",
              "C6KNH7_9INFA_Lee_2018.csv",
              "CALM1_HUMAN_Weile_2017.csv",
              "CAPSD_AAV2S_Sinai_2021.csv",
              "CAR11_HUMAN_Meitlis_2020_gof.csv",
              "CAR11_HUMAN_Meitlis_2020_lof.csv",
              "CAS9_STRP1_Spencer_2017_positive.csv",
              "CASP3_HUMAN_Roychowdhury_2020.csv",
              "CASP7_HUMAN_Roychowdhury_2020.csv",
              "CATR_CHLRE_Tsuboyama_2023_2AMI.csv",
              "CBPA2_HUMAN_Tsuboyama_2023_1O6X.csv",
              "CBS_HUMAN_Sun_2020.csv",
              "CBX4_HUMAN_Tsuboyama_2023_2K28.csv",
              "CCDB_ECOLI_Adkar_2012.csv",
              "CCDB_ECOLI_Tripathi_2016.csv",
              "CCR5_HUMAN_Gill_2023.csv",
              "CD19_HUMAN_Klesmith_2019_FMC_singles.csv",
              "CP2C9_HUMAN_Amorosi_2021_abundance.csv",
              "CP2C9_HUMAN_Amorosi_2021_activity.csv",
              "CSN4_MOUSE_Tsuboyama_2023_1UFM.csv",
              "CUE1_YEAST_Tsuboyama_2023_2MYX.csv",
              "D7PM05_CLYGR_Somermeyer_2022.csv",
              "DLG4_HUMAN_Faure_2021.csv",
              "DLG4_RAT_McLaughlin_2012.csv",
              "DN7A_SACS2_Tsuboyama_2023_1JIC.csv",
              "DNJA1_HUMAN_Tsuboyama_2023_2LO1.csv",
              "DOCK1_MOUSE_Tsuboyama_2023_2M0Y.csv",
              "DYR_ECOLI_Nguyen_2023.csv",
              "DYR_ECOLI_Thompson_2019.csv",
              "ENVZ_ECOLI_Ghose_2023.csv",
              "ENV_HV1B9_DuenasDecamp_2016.csv",
              "ENV_HV1BR_Haddox_2016.csv",
              "EPHB2_HUMAN_Tsuboyama_2023_1F0M.csv",
              "ERBB2_HUMAN_Elazar_2016.csv",
              "ESTA_BACSU_Nutschel_2020.csv",
              "F7YBW8_MESOW_Aakre_2015.csv",
              "F7YBW8_MESOW_Ding_2023.csv",
              "FECA_ECOLI_Tsuboyama_2023_2D1U.csv",
              "FKBP3_HUMAN_Tsuboyama_2023_2KFV.csv",
              "GAL4_YEAST_Kitzman_2015.csv",
              "GCN4_YEAST_Staller_2018.csv",
              "GDIA_HUMAN_Silverstein_2021.csv",
              "GFP_AEQVI_Sarkisyan_2016.csv",
              "GLPA_HUMAN_Elazar_2016.csv",
              "GRB2_HUMAN_Faure_2021.csv",
              "HCP_LAMBD_Tsuboyama_2023_2L6Q.csv",
              "HECD1_HUMAN_Tsuboyama_2023_3DKM.csv",
              "HEM3_HUMAN_Loggerenberg_2023.csv",
              "HIS7_YEAST_Pokusaeva_2019.csv",
              "HMDH_HUMAN_Jiang_2019.csv",
              "HSP82_YEAST_Cote-Hammarlof_2020_growth-H2O2.csv",
              "HSP82_YEAST_Flynn_2019.csv",
              "HSP82_YEAST_Mishra_2016.csv",
              "HXK4_HUMAN_Gersing_2022_activity.csv",
              "HXK4_HUMAN_Gersing_2023_abundance.csv",
              "I6TAH8_I68A0_Doud_2015.csv",
              "IF1_ECOLI_Kelsic_2016.csv",
              "ILF3_HUMAN_Tsuboyama_2023_2L33.csv",
              "ISDH_STAAW_Tsuboyama_2023_2LHR.csv",
              "KCNE1_HUMAN_Muhammad_2023_expression.csv",
              "KCNE1_HUMAN_Muhammad_2023_function.csv",
              "KCNH2_HUMAN_Kozek_2020.csv",
              "KCNJ2_MOUSE_Coyote-Maestas_2022_function.csv",
              "KCNJ2_MOUSE_Coyote-Maestas_2022_surface.csv",
              "KKA2_KLEPN_Melnikov_2014.csv",
              "LGK_LIPST_Klesmith_2015.csv",
              "LYAM1_HUMAN_Elazar_2016.csv",
              "MAFG_MOUSE_Tsuboyama_2023_1K1V.csv",
              "MBD11_ARATH_Tsuboyama_2023_6ACV.csv",
              "MET_HUMAN_Estevam_2023.csv",
              "MK01_HUMAN_Brenan_2016.csv",
              "MLAC_ECOLI_MacRae_2023.csv",
              "MSH2_HUMAN_Jia_2020.csv",
              "MTH3_HAEAE_RockahShmuel_2015.csv",
              "MTHR_HUMAN_Weile_2021.csv",
              "MYO3_YEAST_Tsuboyama_2023_2BTT.csv",
              "NCAP_I34A1_Doud_2015.csv",
              "NKX31_HUMAN_Tsuboyama_2023_2L9R.csv",
              "NPC1_HUMAN_Erwood_2022_HEK293T.csv",
              "NPC1_HUMAN_Erwood_2022_RPE1.csv",
              "NRAM_I33A0_Jiang_2016.csv",
              "NUD15_HUMAN_Suiter_2020.csv",
              "NUSA_ECOLI_Tsuboyama_2023_1WCL.csv",
              "NUSG_MYCTU_Tsuboyama_2023_2MI6.csv",
              "OBSCN_HUMAN_Tsuboyama_2023_1V1C.csv",
              "ODP2_GEOSE_Tsuboyama_2023_1W4G.csv",
              "OPSD_HUMAN_Wan_2019.csv",
              "OTC_HUMAN_Lo_2023.csv",
              "OTU7A_HUMAN_Tsuboyama_2023_2L2D.csv",
              "OXDA_RHOTO_Vanella_2023_activity.csv",
              "OXDA_RHOTO_Vanella_2023_expression.csv",
              "P53_HUMAN_Giacomelli_2018_Null_Etoposide.csv",
              "P53_HUMAN_Giacomelli_2018_Null_Nutlin.csv",
              "P53_HUMAN_Giacomelli_2018_WT_Nutlin.csv",
              "P53_HUMAN_Kotler_2018.csv",
              "P84126_THETH_Chan_2017.csv",
              "PABP_YEAST_Melamed_2013.csv",
              "PAI1_HUMAN_Huttinger_2021.csv",
              "PA_I34A1_Wu_2015.csv",
              "PHOT_CHLRE_Chen_2023.csv",
              "PIN1_HUMAN_Tsuboyama_2023_1I6C.csv",
              "PITX2_HUMAN_Tsuboyama_2023_2L7M.csv",
              "PKN1_HUMAN_Tsuboyama_2023_1URF.csv",
              "POLG_CXB3N_Mattenberger_2021.csv",
              "POLG_DEN26_Suphatrakul_2023.csv",
              "POLG_HCVJF_Qi_2014.csv",
              "POLG_PESV_Tsuboyama_2023_2MXD.csv",
              "PPARG_HUMAN_Majithia_2016.csv",
              "PPM1D_HUMAN_Miller_2022.csv",
              "PR40A_HUMAN_Tsuboyama_2023_1UZC.csv",
              "PRKN_HUMAN_Clausen_2023.csv",
              "PSAE_PICP2_Tsuboyama_2023_1PSE.csv",
              "PTEN_HUMAN_Matreyek_2021.csv",
              "PTEN_HUMAN_Mighell_2018.csv",
              "Q2N0S5_9HIV1_Haddox_2018.csv",
              "Q53Z42_HUMAN_McShan_2019_binding-TAPBPR.csv",
              "Q53Z42_HUMAN_McShan_2019_expression.csv",
              "Q59976_STRSQ_Romero_2015.csv",
              "Q6WV12_9MAXI_Somermeyer_2022.csv",
              "Q837P4_ENTFA_Meier_2023.csv",
              "Q837P5_ENTFA_Meier_2023.csv",
              "Q8WTC7_9CNID_Somermeyer_2022.csv",
              "R1AB_SARS2_Flynn_2022.csv",
              "RAD_ANTMA_Tsuboyama_2023_2CJJ.csv",
              "RAF1_HUMAN_Zinkus-Boltz_2019.csv",
              "RASH_HUMAN_Bandaru_2017.csv",
              "RASK_HUMAN_Weng_2022_abundance.csv",
              "RASK_HUMAN_Weng_2022_binding-DARPin_K55.csv",
              "RBP1_HUMAN_Tsuboyama_2023_2KWH.csv",
              "RCD1_ARATH_Tsuboyama_2023_5OAO.csv",
              "RCRO_LAMBD_Tsuboyama_2023_1ORC.csv",
              "RD23A_HUMAN_Tsuboyama_2023_1IFY.csv",
              "RDRP_I33A0_Li_2023.csv",
              "REV_HV1H2_Fernandes_2016.csv",
              "RFAH_ECOLI_Tsuboyama_2023_2LCL.csv",
              "RL20_AQUAE_Tsuboyama_2023_1GYZ.csv",
              "RL40A_YEAST_Mavor_2016.csv",
              "RL40A_YEAST_Roscoe_2013.csv",
              "RL40A_YEAST_Roscoe_2014.csv",
              "RNC_ECOLI_Weeks_2023.csv",
              "RPC1_BP434_Tsuboyama_2023_1R69.csv",
              "RPC1_LAMBD_Li_2019_high-expression.csv",
              "RPC1_LAMBD_Li_2019_low-expression.csv",
              "RS15_GEOSE_Tsuboyama_2023_1A32.csv",
              "S22A1_HUMAN_Yee_2023_abundance.csv",
              "S22A1_HUMAN_Yee_2023_activity.csv",
              "SAV1_MOUSE_Tsuboyama_2023_2YSB.csv",
              "SBI_STAAM_Tsuboyama_2023_2JVG.csv",
              "SC6A4_HUMAN_Young_2021.csv",
              "SCIN_STAAR_Tsuboyama_2023_2QFF.csv",
              "SCN5A_HUMAN_Glazer_2019.csv",
              "SDA_BACSU_Tsuboyama_2023_1PV0.csv",
              "SERC_HUMAN_Xie_2023.csv",
              "SHOC2_HUMAN_Kwon_2022.csv",
              "SOX30_HUMAN_Tsuboyama_2023_7JJK.csv",
              "SPA_STAAU_Tsuboyama_2023_1LP1.csv",
              "SPG1_STRSG_Olson_2014.csv",
              "SPG1_STRSG_Wu_2016.csv",
              "SPG2_STRSG_Tsuboyama_2023_5UBS.csv",
              "SPIKE_SARS2_Starr_2020_binding.csv",
              "SPIKE_SARS2_Starr_2020_expression.csv",
              "SPTN1_CHICK_Tsuboyama_2023_1TUD.csv",
              "SQSTM_MOUSE_Tsuboyama_2023_2RRU.csv",
              "SR43C_ARATH_Tsuboyama_2023_2N88.csv",
              "SRBS1_HUMAN_Tsuboyama_2023_2O2W.csv",
              "SRC_HUMAN_Ahler_2019.csv",
              "SRC_HUMAN_Chakraborty_2023_binding-DAS_25uM.csv",
              "SRC_HUMAN_Nguyen_2022.csv",
              "SUMO1_HUMAN_Weile_2017.csv",
              "SYUA_HUMAN_Newberry_2020.csv",
              "TADBP_HUMAN_Bolognesi_2019.csv",
              "TAT_HV1BR_Fernandes_2016.csv",
              "TCRG1_MOUSE_Tsuboyama_2023_1E0L.csv",
              "THO1_YEAST_Tsuboyama_2023_2WQG.csv",
              "TNKS2_HUMAN_Tsuboyama_2023_5JRT.csv",
              "TPK1_HUMAN_Weile_2017.csv",
              "TPMT_HUMAN_Matreyek_2018.csv",
              "TPOR_HUMAN_Bridgford_2020.csv",
              "TRPC_SACS2_Chan_2017.csv",
              "TRPC_THEMA_Chan_2017.csv",
              "UBC9_HUMAN_Weile_2017.csv",
              "UBE4B_HUMAN_Tsuboyama_2023_3L1X.csv",
              "UBE4B_MOUSE_Starita_2013.csv",
              "UBR5_HUMAN_Tsuboyama_2023_1I2T.csv",
              "VG08_BPP22_Tsuboyama_2023_2GP8.csv",
              "VILI_CHICK_Tsuboyama_2023_1YU5.csv",
              "VKOR1_HUMAN_Chiasson_2020_abundance.csv",
              "VKOR1_HUMAN_Chiasson_2020_activity.csv",
              "VRPI_BPT7_Tsuboyama_2023_2WNM.csv",
              "YAIA_ECOLI_Tsuboyama_2023_2KVT.csv",
              "YAP1_HUMAN_Araya_2012.csv",
              "YNZC_BACSU_Tsuboyama_2023_2JVD.csv"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Dataset:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_3f1ce42fef2d49d79060bb9ce4c8c31d",
            "style": "IPY_MODEL_82d4d01f086c4cd2a9b456e6f01228f4"
          }
        },
        "3f1ce42fef2d49d79060bb9ce4c8c31d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "70%"
          }
        },
        "82d4d01f086c4cd2a9b456e6f01228f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec67f28adfa347019114ab0fa73a295c": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_38856fa5138e41529dc948a22e325f4e",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Selected dataset:\n",
                  "/content/proteingym/DMS_ProteinGym_substitutions/A0A140D2T1_ZIKV_Sourisseau_2019.csv\n"
                ]
              }
            ]
          }
        },
        "38856fa5138e41529dc948a22e325f4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bordin89/ML4NGP_tutorials/blob/main/ml4ngp_2_profam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß¨ Generating novel sequences and structures with ProFam-1\n",
        "\n",
        "This notebook presents an end-to-end workflow for **protein sequence generation and structural validation** using **ProFam-1**, a family-aware generative model trained on protein domain and family information. The goal of the workshop is to guide you from an input protein sequence, through controlled generative modelling, to quantitative and visual structural comparison against a reference structure.\n",
        "\n",
        "The notebook is designed to be fully reproducible in a Google Colab environment with GPU support and does not require Flash Attention. All steps are executed interactively, allowing participants to explore how generative parameters affect sequence quality and downstream structural fidelity.\n",
        "\n",
        "We begin by setting up the computational environment and installing the required dependencies. The ProFam repository is cloned, and a pretrained ProFam-1 checkpoint is located and prepared for inference. Care is taken to ensure compatibility with standard Colab GPU instances, avoiding optional components that are not universally available.\n",
        "\n",
        "Next, an input protein sequence is provided. By default, the notebook uses a known PETase sequence from UniProt as a single-sequence prompt, but participants may alternatively paste their own sequence directly into the notebook. Any extraneous whitespace or line breaks are removed automatically, and the sequence is written to FASTA format for downstream use.\n",
        "\n",
        "Using ProFam-1, one or more novel protein sequences are then generated, conditioned on the input sequence. The generation step exposes a small number of adjustable parameters, such as the number of sequences to generate and the sampling temperature, while keeping most model settings fixed to sensible defaults. Additional quality filters are applied to enforce reasonable sequence lengths and minimum similarity to the prompt, helping to avoid pathological or truncated outputs.\n",
        "\n",
        "Structure prediction is performed outside the notebook using a tool such as AlphaFold or ESMFold. Once predicted, the structures of both the generated sequence and the original input sequence are uploaded back into the notebook in either PDB or mmCIF format. These structures form the basis for structural validation.\n",
        "\n",
        "Structural comparison is carried out using **TM-align**, which provides quantitative measures of similarity including TM-score, RMSD, and aligned length. The TM-score is particularly informative: values above 0.5 generally indicate a shared fold, while values above 0.8 suggest strong structural agreement. These metrics allow an objective assessment of whether the generated sequence preserves the overall fold of the reference protein.\n",
        "\n",
        "Finally, the two structures are superposed and visualised together using **NGLView** in cartoon (ribbon/strand) representation. The generated structure is rigidly transformed onto the reference structure using the rotation matrix produced by TM-align, allowing direct visual inspection of conserved cores, flexible regions, and any structural deviations. This final step helps connect quantitative scores to intuitive, three-dimensional understanding.\n",
        "\n",
        "By the end of this notebook, you will have walked through a complete generative protein design loop, from sequence generation to structure-based validation, and gained practical insight into how modern protein language models can be evaluated using structural biology tools.\n",
        "\n",
        "**Variant Scoring with Deep Mutational Scanning (ProteinGym)**\n",
        "\n",
        "In addition to sequence generation and structural validation, the notebook now includes a variant scoring module using experimental Deep Mutational Scanning (DMS) data from the ProteinGym benchmark.\n",
        "\n",
        "Whereas generative modelling asks ‚ÄúCan we create new plausible sequences?‚Äù, variant scoring asks a different question:\n",
        "\n",
        "Can ProFam-1 correctly rank mutated variants according to experimental functional measurements?\n",
        "\n",
        "This section demonstrates how ProFam-1 can be used as a fitness predictor, evaluating mutated sequences by their conditional likelihood under a family-aware model.\n",
        "\n",
        "The workflow proceeds as follows:\n",
        "\t1.\tA ProteinGym DMS dataset is downloaded.\n",
        "\t2.\tThe corresponding wild-type (WT) sequence is retrieved from UniProt.\n",
        "\t3.\tTwo inputs are prepared:\n",
        "\t‚Ä¢\tconditioning.fasta ‚Äì the WT sequence (or optionally a small functional family set)\n",
        "\t‚Ä¢\tcandidates.fasta ‚Äì mutated variants extracted from the DMS dataset\n",
        "\t4.\tProFam-1 scores each variant using score_sequences.py.\n",
        "\t5.\tModel scores are compared against experimental measurements using:\n",
        "\t‚Ä¢\tSpearman correlation\n",
        "\t‚Ä¢\tROC-AUC (where applicable)\n",
        "\t‚Ä¢\tVisualisation of score‚Äìfitness relationships\n",
        "\n",
        "This extension highlights ProFam-1‚Äôs ability not only to generate sequences, but also to:\n",
        "\t‚Ä¢\tEvaluate mutational effects\n",
        "\t‚Ä¢\tRank variants by predicted functional fitness\n",
        "\t‚Ä¢\tQuantitatively benchmark against real experimental data\n",
        "\n",
        "Together with the generative and structural components, this creates a more complete workflow:\n",
        "\n",
        "Generation ‚Üí Structural validation ‚Üí Functional variant ranking\n",
        "\n",
        "By incorporating DMS-based evaluation, the notebook now demonstrates both the creative and predictive capabilities of family-aware protein language models."
      ],
      "metadata": {
        "id": "jtC3R7aciTht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1) GPU sanity check\n",
        "\n",
        "import torch, subprocess\n",
        "\n",
        "print(\"Torch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "    print(\"CUDA version (torch):\", torch.version.cuda)\n",
        "\n",
        "# Optional: show nvidia-smi if available\n",
        "try:\n",
        "    out = subprocess.check_output([\"nvidia-smi\"], text=True)\n",
        "    print(\"\\n\" + out[:1500])\n",
        "except Exception:\n",
        "    print(\"nvidia-smi not available\")"
      ],
      "metadata": {
        "id": "QtenLPbjgB7d",
        "outputId": "a087f5ae-8c18-4dab-f6a9-cdd08dd4b8e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch version: 2.9.0+cu128\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n",
            "CUDA version (torch): 12.8\n",
            "\n",
            "Thu Feb 19 10:15:31 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8             10W /   70W |       3MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|======================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2) Clone ProFam\n",
        "\n",
        "import os, pathlib\n",
        "\n",
        "BASE_DIR = pathlib.Path(\"/content\").resolve()\n",
        "WORK_DIR = BASE_DIR / \"profam_workshop\"\n",
        "WORK_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "os.chdir(WORK_DIR)\n",
        "print(\"Working directory:\", WORK_DIR)\n",
        "\n",
        "if not (WORK_DIR / \"profam\").exists():\n",
        "    !git clone https://github.com/alex-hh/profam.git\n",
        "else:\n",
        "    print(\"ProFam repository already present\")\n",
        "\n",
        "%cd {WORK_DIR / \"profam\"}\n",
        "!git rev-parse --short HEAD"
      ],
      "metadata": {
        "id": "ddgjQqXPgocQ",
        "outputId": "fa423449-ba2d-46d8-b16d-8db41da2b949",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working directory: /content/profam_workshop\n",
            "Cloning into 'profam'...\n",
            "remote: Enumerating objects: 8337, done.\u001b[K\n",
            "remote: Counting objects: 100% (485/485), done.\u001b[K\n",
            "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
            "remote: Total 8337 (delta 443), reused 418 (delta 412), pack-reused 7852 (from 3)\u001b[K\n",
            "Receiving objects: 100% (8337/8337), 1.42 MiB | 19.66 MiB/s, done.\n",
            "Resolving deltas: 100% (6252/6252), done.\n",
            "/content/profam_workshop/profam\n",
            "4f89b22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3) Install ProFam (GPU runtime, no flash-attn, Colab-friendly)\n",
        "\n",
        "import re, pathlib, os\n",
        "\n",
        "repo = pathlib.Path(\"/content/profam_workshop/profam\").resolve()\n",
        "os.chdir(repo)\n",
        "print(\"Repository:\", repo)\n",
        "\n",
        "# Ensure up-to-date build tools\n",
        "!pip -q install -U pip setuptools wheel\n",
        "\n",
        "req_in = repo / \"requirements.txt\"\n",
        "if not req_in.exists():\n",
        "    raise FileNotFoundError(f\"Missing {req_in}\")\n",
        "\n",
        "# Packages we deliberately do not override in Colab\n",
        "SKIP_PREFIXES = (\n",
        "    \"flash-attn\", \"flash_attn\",\n",
        "    \"numpy\", \"pandas\", \"requests\",\n",
        "    \"torch\", \"torchvision\", \"torchaudio\",\n",
        "    \"jax\", \"jaxlib\",\n",
        ")\n",
        "\n",
        "filtered = []\n",
        "removed = []\n",
        "\n",
        "for ln in req_in.read_text().splitlines():\n",
        "    s = ln.strip()\n",
        "    if not s or s.startswith(\"#\"):\n",
        "        filtered.append(ln)\n",
        "        continue\n",
        "\n",
        "    head = re.split(r\"[<>=!\\s\\[]\", s, maxsplit=1)[0].lower()\n",
        "\n",
        "    if any(head.startswith(p) for p in SKIP_PREFIXES):\n",
        "        removed.append(ln)\n",
        "        continue\n",
        "\n",
        "    filtered.append(ln)\n",
        "\n",
        "req_out = repo / \"requirements.colab_noflash.txt\"\n",
        "req_out.write_text(\"\\n\".join(filtered) + \"\\n\")\n",
        "\n",
        "print(f\"Wrote {req_out.name}\")\n",
        "\n",
        "if removed:\n",
        "    print(\"Skipped packages:\")\n",
        "    for r in removed:\n",
        "        print(\" \", r)\n",
        "\n",
        "# Install filtered dependencies\n",
        "!pip -q install -r requirements.colab_noflash.txt\n",
        "\n",
        "# Patch common Colab/runtime dependencies\n",
        "!pip -q install \\\n",
        "    \"pandas==2.2.2\" \\\n",
        "    \"requests==2.32.4\" \\\n",
        "    \"packaging>=24.2\" \\\n",
        "    \"typing-extensions>=4.12.0\" \\\n",
        "    \"xxhash>=3.5.0\" \\\n",
        "    \"jedi>=0.16\"\n",
        "\n",
        "# Install ProFam in editable mode\n",
        "!pip -q install -e .\n",
        "\n",
        "print(\"ProFam installation complete.\")"
      ],
      "metadata": {
        "id": "OgVyS5BKgteH",
        "outputId": "b36c20ae-a0e8-4a50-bcaf-f4bdd6a59639",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repository: /content/profam_workshop/profam\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mWrote requirements.colab_noflash.txt\n",
            "Skipped packages:\n",
            "  numpy==1.26.4\n",
            "  pandas==2.3.3\n",
            "  requests==2.32.2\n",
            "  torch==2.6.0\n",
            "  torchvision==0.21.0\n",
            "  torchaudio==2.6.0\n",
            "  torchmetrics==1.8.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "db-dtypes 1.5.0 requires packaging>=24.2.0, but you have packaging 24.0 which is incompatible.\n",
            "google-cloud-bigquery 3.40.1 requires packaging>=24.2.0, but you have packaging 24.0 which is incompatible.\n",
            "pytensor 2.37.0 requires filelock>=3.15, but you have filelock 3.14.0 which is incompatible.\n",
            "peft 0.18.1 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.24.6 which is incompatible.\n",
            "diffusers 0.36.0 requires huggingface-hub<2.0,>=0.34.0, but you have huggingface-hub 0.24.6 which is incompatible.\n",
            "alembic 1.18.4 requires typing-extensions>=4.12, but you have typing-extensions 4.11.0 which is incompatible.\n",
            "langgraph 1.0.8 requires xxhash>=3.5.0, but you have xxhash 3.4.1 which is incompatible.\n",
            "xarray 2025.12.0 requires packaging>=24.1, but you have packaging 24.0 which is incompatible.\n",
            "grpcio 1.78.0 requires typing-extensions~=4.12, but you have typing-extensions 4.11.0 which is incompatible.\n",
            "typing-inspection 0.4.2 requires typing-extensions>=4.12.0, but you have typing-extensions 4.11.0 which is incompatible.\n",
            "mcp 1.26.0 requires pydantic<3.0.0,>=2.11.0, but you have pydantic 2.9.2 which is incompatible.\n",
            "torchaudio 2.9.0+cu128 requires torch==2.9.0, but you have torch 2.6.0 which is incompatible.\n",
            "torchvision 0.24.0+cu128 requires torch==2.9.0, but you have torch 2.6.0 which is incompatible.\n",
            "typeguard 4.4.4 requires typing_extensions>=4.14.0, but you have typing-extensions 4.11.0 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.3.1 which is incompatible.\n",
            "gradio 5.50.0 requires huggingface-hub<2.0,>=0.33.5, but you have huggingface-hub 0.24.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lightning 2.4.0 requires packaging<25.0,>=20.0, but you have packaging 26.0 which is incompatible.\n",
            "peft 0.18.1 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.24.6 which is incompatible.\n",
            "diffusers 0.36.0 requires huggingface-hub<2.0,>=0.34.0, but you have huggingface-hub 0.24.6 which is incompatible.\n",
            "mcp 1.26.0 requires pydantic<3.0.0,>=2.11.0, but you have pydantic 2.9.2 which is incompatible.\n",
            "torchaudio 2.9.0+cu128 requires torch==2.9.0, but you have torch 2.6.0 which is incompatible.\n",
            "torchvision 0.24.0+cu128 requires torch==2.9.0, but you have torch 2.6.0 which is incompatible.\n",
            "gradio 5.50.0 requires huggingface-hub<2.0,>=0.33.5, but you have huggingface-hub 0.24.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building editable for profam (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.18.1 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.24.6 which is incompatible.\n",
            "diffusers 0.36.0 requires huggingface-hub<2.0,>=0.34.0, but you have huggingface-hub 0.24.6 which is incompatible.\n",
            "torchaudio 2.9.0+cu128 requires torch==2.9.0, but you have torch 2.6.0 which is incompatible.\n",
            "torchvision 0.24.0+cu128 requires torch==2.9.0, but you have torch 2.6.0 which is incompatible.\n",
            "gradio 5.50.0 requires huggingface-hub<2.0,>=0.33.5, but you have huggingface-hub 0.24.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mProFam installation complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4) Download ProFam model checkpoint from Hugging Face\n",
        "\n",
        "import os, pathlib\n",
        "\n",
        "repo = pathlib.Path(\"/content/profam_workshop/profam\").resolve()\n",
        "os.chdir(repo)\n",
        "\n",
        "os.environ[\"HF_HOME\"] = \"/content/hf_cache\"\n",
        "pathlib.Path(os.environ[\"HF_HOME\"]).mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "!python scripts/hf_download_checkpoint.py\n",
        "\n",
        "print(\"Checkpoint download complete.\")"
      ],
      "metadata": {
        "id": "_AE6Ezw9rIHX",
        "outputId": "d9865e0f-7dd8-41ab-a290-1b6b075744b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:1212: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
            "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
            "  warnings.warn(\n",
            "Fetching 5 files:   0% 0/5 [00:00<?, ?it/s]\n",
            "config.yaml: 13.3kB [00:00, 10.6MB/s]\n",
            "\n",
            "gym_config.yaml: 0.00B [00:00, ?B/s]\u001b[A\n",
            "\n",
            ".gitattributes: 1.52kB [00:00, 8.20MB/s]\n",
            "gym_config.yaml: 6.55kB [00:00, 4.28MB/s]\n",
            "Fetching 5 files:  20% 1/5 [00:00<00:00,  6.04it/s]\n",
            "README.md: 100% 24.0/24.0 [00:00<00:00, 146kB/s]\n",
            "\n",
            "last.ckpt:   0% 0.00/1.51G [00:00<?, ?B/s]\u001b[A\n",
            "last.ckpt:   1% 21.0M/1.51G [00:00<00:09, 157MB/s]\u001b[A\n",
            "last.ckpt:   3% 52.4M/1.51G [00:00<00:06, 222MB/s]\u001b[A\n",
            "last.ckpt:   6% 83.9M/1.51G [00:00<00:05, 256MB/s]\u001b[A\n",
            "last.ckpt:   8% 115M/1.51G [00:00<00:06, 223MB/s] \u001b[A\n",
            "last.ckpt:  10% 147M/1.51G [00:00<00:05, 244MB/s]\u001b[A\n",
            "last.ckpt:  12% 178M/1.51G [00:00<00:06, 216MB/s]\u001b[A\n",
            "last.ckpt:  14% 210M/1.51G [00:00<00:05, 220MB/s]\u001b[A\n",
            "last.ckpt:  16% 241M/1.51G [00:01<00:05, 224MB/s]\u001b[A\n",
            "last.ckpt:  18% 273M/1.51G [00:01<00:05, 234MB/s]\u001b[A\n",
            "last.ckpt:  21% 315M/1.51G [00:01<00:04, 257MB/s]\u001b[A\n",
            "last.ckpt:  23% 346M/1.51G [00:01<00:04, 267MB/s]\u001b[A\n",
            "last.ckpt:  25% 377M/1.51G [00:01<00:04, 264MB/s]\u001b[A\n",
            "last.ckpt:  27% 409M/1.51G [00:01<00:04, 268MB/s]\u001b[A\n",
            "last.ckpt:  29% 440M/1.51G [00:01<00:03, 273MB/s]\u001b[A\n",
            "last.ckpt:  31% 472M/1.51G [00:01<00:03, 275MB/s]\u001b[A\n",
            "last.ckpt:  33% 503M/1.51G [00:02<00:03, 282MB/s]\u001b[A\n",
            "last.ckpt:  35% 535M/1.51G [00:02<00:03, 290MB/s]\u001b[A\n",
            "last.ckpt:  38% 577M/1.51G [00:02<00:03, 302MB/s]\u001b[A\n",
            "last.ckpt:  41% 619M/1.51G [00:02<00:02, 311MB/s]\u001b[A\n",
            "last.ckpt:  43% 650M/1.51G [00:02<00:02, 312MB/s]\u001b[A\n",
            "last.ckpt:  46% 692M/1.51G [00:02<00:02, 318MB/s]\u001b[A\n",
            "last.ckpt:  49% 734M/1.51G [00:02<00:02, 279MB/s]\u001b[A\n",
            "last.ckpt:  51% 765M/1.51G [00:02<00:02, 279MB/s]\u001b[A\n",
            "last.ckpt:  53% 807M/1.51G [00:03<00:02, 273MB/s]\u001b[A\n",
            "last.ckpt:  56% 839M/1.51G [00:03<00:02, 262MB/s]\u001b[A\n",
            "last.ckpt:  58% 870M/1.51G [00:03<00:02, 273MB/s]\u001b[A\n",
            "last.ckpt:  60% 902M/1.51G [00:03<00:02, 257MB/s]\u001b[A\n",
            "last.ckpt:  62% 933M/1.51G [00:03<00:02, 259MB/s]\u001b[A\n",
            "last.ckpt:  64% 965M/1.51G [00:05<00:12, 45.5MB/s]\u001b[A\n",
            "last.ckpt:  67% 1.01G/1.51G [00:05<00:07, 66.0MB/s]\u001b[A\n",
            "last.ckpt:  69% 1.05G/1.51G [00:05<00:05, 90.8MB/s]\u001b[A\n",
            "last.ckpt:  72% 1.09G/1.51G [00:05<00:03, 119MB/s] \u001b[A\n",
            "last.ckpt:  75% 1.13G/1.51G [00:06<00:02, 148MB/s]\u001b[A\n",
            "last.ckpt:  77% 1.16G/1.51G [00:06<00:02, 169MB/s]\u001b[A\n",
            "last.ckpt:  80% 1.21G/1.51G [00:06<00:01, 199MB/s]\u001b[A\n",
            "last.ckpt:  82% 1.24G/1.51G [00:06<00:01, 218MB/s]\u001b[A\n",
            "last.ckpt:  84% 1.27G/1.51G [00:06<00:01, 238MB/s]\u001b[A\n",
            "last.ckpt:  87% 1.31G/1.51G [00:06<00:00, 262MB/s]\u001b[A\n",
            "last.ckpt:  90% 1.35G/1.51G [00:06<00:00, 280MB/s]\u001b[A\n",
            "last.ckpt:  92% 1.39G/1.51G [00:06<00:00, 290MB/s]\u001b[A\n",
            "last.ckpt:  95% 1.44G/1.51G [00:07<00:00, 292MB/s]\u001b[A\n",
            "last.ckpt:  97% 1.47G/1.51G [00:07<00:00, 277MB/s]\u001b[A\n",
            "last.ckpt: 100% 1.51G/1.51G [00:07<00:00, 204MB/s]\n",
            "Fetching 5 files: 100% 5/5 [00:07<00:00,  1.52s/it]\n",
            "Downloaded to: /content/profam_workshop/profam/model_checkpoints/profam-1\n",
            "Checkpoint download complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5) Fix Colab torch/torchvision mismatch (remove torchvision)\n",
        "\n",
        "# Remove torchvision to prevent torchmetrics/lightning import issues\n",
        "!pip -q uninstall -y torchvision || true\n",
        "\n",
        "print(\"torchvision removed.\")"
      ],
      "metadata": {
        "id": "wRl_-dT7xpC4",
        "outputId": "77570be0-0966-4582-d901-a7c9f82f8731",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torchvision removed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 6) Show ProFam CLI help (score + generate)\n",
        "\n",
        "import pathlib, os\n",
        "\n",
        "repo = pathlib.Path(\"/content/profam_workshop/profam\").resolve()\n",
        "os.chdir(repo)\n",
        "\n",
        "print(\"=== score_sequences.py ===\")\n",
        "!python scripts/score_sequences.py -h | head -n 120\n",
        "\n",
        "print(\"\\n=== generate_sequences.py ===\")\n",
        "!python scripts/generate_sequences.py -h | head -n 120"
      ],
      "metadata": {
        "id": "ZkCDYcH-u5Vt",
        "outputId": "4a0d4128-2753-4aa7-9962-f0d9c7a37a7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== score_sequences.py ===\n",
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
            "0it [00:00, ?it/s]\n",
            "/usr/local/lib/python3.12/dist-packages/lightning_utilities/core/imports.py:14: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "2026-02-19 10:21:53.758875: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1771496513.960796    2816 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1771496514.017127    2816 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1771496514.439942    2816 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771496514.439979    2816 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771496514.439983    2816 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771496514.439991    2816 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-19 10:21:54.482432: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "usage: score_sequences.py [-h] [--checkpoint_dir CHECKPOINT_DIR]\n",
            "                          [--conditioning_fasta CONDITIONING_FASTA]\n",
            "                          [--candidates_file CANDIDATES_FILE]\n",
            "                          [--save_dir SAVE_DIR] [--device DEVICE]\n",
            "                          [--dtype {float32,float16,bfloat16}] [--seed SEED]\n",
            "                          [--max_tokens MAX_TOKENS]\n",
            "                          [--scoring_max_tokens SCORING_MAX_TOKENS]\n",
            "                          [--ensemble_number ENSEMBLE_NUMBER]\n",
            "                          [--use_diversity_weights | --no-use_diversity_weights]\n",
            "                          [--diversity_theta DIVERSITY_THETA]\n",
            "                          [--recompute_diversity_weights | --no-recompute_diversity_weights]\n",
            "                          [--attn_implementation {sdpa,flash_attention_2,eager}]\n",
            "\n",
            "Compute conditional likelihoods of candidate sequences given conditioning\n",
            "sequences\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --checkpoint_dir CHECKPOINT_DIR\n",
            "                        Checkpoint run directory (contains\n",
            "                        checkpoints/last.ckpt)\n",
            "  --conditioning_fasta CONDITIONING_FASTA\n",
            "                        Path to conditioning FASTA/MSA file\n",
            "  --candidates_file CANDIDATES_FILE\n",
            "                        Path to candidate sequences FASTA file or csv file\n",
            "                        with columns: 'mutated_sequence', and optionally\n",
            "                        'DMS_score'\n",
            "  --save_dir SAVE_DIR   Directory to save output files\n",
            "  --device DEVICE\n",
            "  --dtype {float32,float16,bfloat16}\n",
            "  --seed SEED\n",
            "  --max_tokens MAX_TOKENS\n",
            "                        Token budget (prompt+completion) used for batch size\n",
            "                        heuristics\n",
            "  --scoring_max_tokens SCORING_MAX_TOKENS\n",
            "                        Token budget used ONLY to dynamically set the scoring\n",
            "                        batch size to stay within memory constraints. This is\n",
            "                        typically higher than --max_tokens.\n",
            "  --ensemble_number ENSEMBLE_NUMBER\n",
            "                        Number of prompts used to generate the ensemble score\n",
            "  --use_diversity_weights, --no-use_diversity_weights\n",
            "                        If set, sample conditioning sequences with homology-\n",
            "                        based diversity weights (1/#neighbors).\n",
            "  --diversity_theta DIVERSITY_THETA\n",
            "                        Theta used for homology neighbor definition when\n",
            "                        computing diversity weights.\n",
            "  --recompute_diversity_weights, --no-recompute_diversity_weights\n",
            "                        If set, ignore any on-disk cached weights and\n",
            "                        recompute.\n",
            "  --attn_implementation {sdpa,flash_attention_2,eager}\n",
            "                        Override attention implementation before model init\n",
            "                        (e.g. flash_attention_2)\n",
            "\n",
            "=== generate_sequences.py ===\n",
            "/usr/local/lib/python3.12/dist-packages/lightning_utilities/core/imports.py:14: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "2026-02-19 10:22:11.679044: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1771496531.698264    2958 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1771496531.704216    2958 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1771496531.720195    2958 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771496531.720223    2958 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771496531.720227    2958 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771496531.720231    2958 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-19 10:22:11.724831: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "usage: generate_sequences.py [-h] [--checkpoint_dir CHECKPOINT_DIR]\n",
            "                             [--file_path FILE_PATH] [--save_dir SAVE_DIR]\n",
            "                             [--sampler {ensemble,single}]\n",
            "                             [--num_prompts_in_ensemble NUM_PROMPTS_IN_ENSEMBLE]\n",
            "                             [--num_samples NUM_SAMPLES]\n",
            "                             [--max_tokens MAX_TOKENS]\n",
            "                             [--max_generated_length MAX_GENERATED_LENGTH]\n",
            "                             [--temperature TEMPERATURE] [--top_p TOP_P]\n",
            "                             [--reduction {mean_probs,sum_log_probs}]\n",
            "                             [--device DEVICE]\n",
            "                             [--dtype {float32,float16,bfloat16}]\n",
            "                             [--continuous_sampling]\n",
            "                             [--max_sequence_length_multiplier MAX_SEQUENCE_LENGTH_MULTIPLIER]\n",
            "                             [--minimum_sequence_length_proportion MINIMUM_SEQUENCE_LENGTH_PROPORTION]\n",
            "                             [--minimum_sequence_identity MINIMUM_SEQUENCE_IDENTITY]\n",
            "                             [--maximum_retries MAXIMUM_RETRIES]\n",
            "                             [--task_index TASK_INDEX] [--num_tasks NUM_TASKS]\n",
            "                             [--disable_repeat_guard] [--seed SEED]\n",
            "                             [--attn_implementation {sdpa,flash_attention_2,eager}]\n",
            "\n",
            "Debug ensemble decoder sampling\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --checkpoint_dir CHECKPOINT_DIR\n",
            "                        Checkpoint run directory (contains .hydra)\n",
            "  --file_path FILE_PATH\n",
            "                        Filepath for input FASTA/MSA files (e.g.\n",
            "                        'data/4_1_1_39_cluster.filtered.fasta' or\n",
            "                        '../data/val/*.a3m')\n",
            "  --save_dir SAVE_DIR   Directory to save generated FASTA files\n",
            "  --sampler {ensemble,single}\n",
            "                        Sampler type: ensemble or single\n",
            "  --num_prompts_in_ensemble NUM_PROMPTS_IN_ENSEMBLE\n",
            "  --num_samples NUM_SAMPLES\n",
            "  --max_tokens MAX_TOKENS\n",
            "  --max_generated_length MAX_GENERATED_LENGTH\n",
            "  --temperature TEMPERATURE\n",
            "  --top_p TOP_P         Nucleus sampling probability mass (0<p<=1)\n",
            "  --reduction {mean_probs,sum_log_probs}\n",
            "  --device DEVICE\n",
            "  --dtype {float32,float16,bfloat16}\n",
            "  --continuous_sampling\n",
            "                        Ignore [SEP] EOS and generate until token budget; drop\n",
            "                        final partial segment\n",
            "  --max_sequence_length_multiplier MAX_SEQUENCE_LENGTH_MULTIPLIER\n",
            "                        Limits the maximum generated length to be no longer\n",
            "                        than this factor longer than the longest sequence in\n",
            "                        the prompt\n",
            "  --minimum_sequence_length_proportion MINIMUM_SEQUENCE_LENGTH_PROPORTION\n",
            "                        Discard sequences that end with length < this\n",
            "                        proportion times the minimum sequence length in the\n",
            "                        prompt\n",
            "  --minimum_sequence_identity MINIMUM_SEQUENCE_IDENTITY\n",
            "                        Discard sequences that have an aligned identity\n",
            "                        fraction less than this quantity\n",
            "  --maximum_retries MAXIMUM_RETRIES\n",
            "                        If a sequence is aborted by filters, retry up to this\n",
            "                        many times before returning the last attempt\n",
            "  --task_index TASK_INDEX\n",
            "                        Task index\n",
            "  --num_tasks NUM_TASKS\n",
            "                        Number of tasks\n",
            "  --disable_repeat_guard\n",
            "                        Disable repeat guard: repeat guard aborts and retries\n",
            "                        the sequence generation if it detects too many repeats\n",
            "  --seed SEED           Random seed for reproducible sampling\n",
            "  --attn_implementation {sdpa,flash_attention_2,eager}\n",
            "                        Override attention implementation before model init\n",
            "                        (e.g. flash_attention_2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 7) Create prompt FASTA (default PETase or user-provided sequence)\n",
        "\n",
        "import pathlib, textwrap, re, os\n",
        "\n",
        "repo = pathlib.Path(\"/content/profam_workshop/profam\").resolve()\n",
        "os.chdir(repo)\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# DISCLAIMER\n",
        "# -----------------------------------------------------------------------------\n",
        "# ProFam can also take a multi-sequence FASTA or an aligned MSA (e.g. A3M).\n",
        "#\n",
        "# - A single sequence is sufficient and recommended for sequence generation.\n",
        "# - Multiple FASTA entries are treated as independent prompts.\n",
        "# - Providing an MSA can be used to condition generation on a protein family,\n",
        "#   but alignment is NOT required for generation.\n",
        "# - MSAs are primarily important for variant scoring, not for generation.\n",
        "#\n",
        "# For this workshop, we use a single-sequence prompt by default.\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "# =========================\n",
        "# USER CHOICES\n",
        "# =========================\n",
        "USE_DEFAULT = True  #@param {type:\"boolean\"}\n",
        "\n",
        "# If USE_DEFAULT = False, paste either:\n",
        "#  - FASTA (one or more records), OR\n",
        "#  - a raw amino-acid sequence\n",
        "USER_SEQUENCE_TEXT = \"MNKFLALALAVSLSASAAPVPSQAFGDLGKDTVAV GDSGVPVSPQTDPSATVGRRLTAAALDALDAGADVV VPGSAGTFSVTLGATNATVVGVDLQLAGADATVTLA AGATGNSGGYVVWGGHGTQATQVVAGLPQLAVAGAD VVIVDNNRAGADVVAVSGGTTSTTTW\"  #@param {type:\"string\"}\n",
        "\n",
        "USER_SEQ_NAME = \"TEST\"  #@param {type:\"string\"}\n",
        "\n",
        "out_fa = repo / \"prompts.fasta\"\n",
        "\n",
        "# =========================\n",
        "# DEFAULT: PETase (Ideonella sakaiensis)\n",
        "# UniProt: A0A0K8P6T7\n",
        "# =========================\n",
        "DEFAULT_FASTA = textwrap.dedent(\"\"\"\\\n",
        ">PETase_A0A0K8P6T7\n",
        "MNFPRASRLMQAAVLGGLMAVSAAATAQTNPYARGPNPTAASLEASAGPFTVRSFTVSRP\n",
        "SGYGAGTVYYPTNAGGTVGAIAIVPGYTARQSSIKWWGPRLASHGFVVITIDTNSTLDQP\n",
        "SSRSSQQMAALRQVASLNGTSSSPIYGKVDTARMGVMGWSMGGGGSLISAANNPSLKAAA\n",
        "PQAPWDSSTNFSSVTVPTLIFACENDSIAPVNSSALPIYDSMSRNAKQFLEINGGSHSCA\n",
        "NSGNSNQALIGKKGVAWMKRFMDNDTRYSTFACENPNSTRVSDFRTANCS\n",
        "\"\"\")\n",
        "\n",
        "AA_RE = re.compile(r\"^[ACDEFGHIKLMNPQRSTVWYBXZJUO\\-\\.\\s]+$\", re.IGNORECASE)\n",
        "\n",
        "def normalize_raw_sequence(s: str) -> str:\n",
        "    \"\"\"\n",
        "    Accept raw amino-acid sequences that may contain spaces or newlines.\n",
        "    Strip everything except letters A‚ÄìZ and uppercase.\n",
        "    \"\"\"\n",
        "    s = s.strip().upper()\n",
        "    s = re.sub(r\"\\s+\", \"\", s)\n",
        "    s = re.sub(r\"[^A-Z]\", \"\", s)\n",
        "    return s\n",
        "\n",
        "def to_fasta_from_raw(seq: str, name: str) -> str:\n",
        "    seq = normalize_raw_sequence(seq)\n",
        "    if not seq:\n",
        "        raise ValueError(\"Sequence is empty after cleaning.\")\n",
        "    wrapped = \"\\n\".join(seq[i:i+60] for i in range(0, len(seq), 60))\n",
        "    return f\">{name}\\n{wrapped}\\n\"\n",
        "\n",
        "def is_fasta(txt: str) -> bool:\n",
        "    return txt.lstrip().startswith(\">\")\n",
        "\n",
        "# =========================\n",
        "# WRITE FASTA\n",
        "# =========================\n",
        "if USE_DEFAULT:\n",
        "    out_fa.write_text(DEFAULT_FASTA)\n",
        "    print(\"Using default PETase sequence (UniProt QRG82925)\")\n",
        "else:\n",
        "    txt = (USER_SEQUENCE_TEXT or \"\").strip()\n",
        "    if not txt:\n",
        "        raise ValueError(\"USE_DEFAULT is False but USER_SEQUENCE_TEXT is empty.\")\n",
        "\n",
        "    if is_fasta(txt):\n",
        "        out_fa.write_text(txt.strip() + \"\\n\")\n",
        "        print(\"Using user-provided FASTA (single or multiple sequences)\")\n",
        "    else:\n",
        "        if not AA_RE.match(txt.replace(\"\\n\", \"\")):\n",
        "            raise ValueError(\"Input is neither FASTA nor a valid amino-acid sequence.\")\n",
        "        out_fa.write_text(to_fasta_from_raw(txt, USER_SEQ_NAME))\n",
        "        print(\"Using user-provided raw sequence\")\n",
        "\n",
        "print(\"\\nNote:\")\n",
        "print(\"This FASTA can contain a single sequence, multiple sequences, or an MSA.\")\n",
        "print(\"For generation, alignment is optional; for scoring, MSAs are recommended.\")\n",
        "\n",
        "print(\"\\n--- prompts.fasta ---\")\n",
        "print(out_fa.read_text())"
      ],
      "metadata": {
        "id": "wkZQIvrhzZox",
        "outputId": "7e6ac929-91aa-4162-80ef-f7cde21218b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using default PETase sequence (UniProt QRG82925)\n",
            "\n",
            "Note:\n",
            "This FASTA can contain a single sequence, multiple sequences, or an MSA.\n",
            "For generation, alignment is optional; for scoring, MSAs are recommended.\n",
            "\n",
            "--- prompts.fasta ---\n",
            ">PETase_A0A0K8P6T7\n",
            "MNFPRASRLMQAAVLGGLMAVSAAATAQTNPYARGPNPTAASLEASAGPFTVRSFTVSRP\n",
            "SGYGAGTVYYPTNAGGTVGAIAIVPGYTARQSSIKWWGPRLASHGFVVITIDTNSTLDQP\n",
            "SSRSSQQMAALRQVASLNGTSSSPIYGKVDTARMGVMGWSMGGGGSLISAANNPSLKAAA\n",
            "PQAPWDSSTNFSSVTVPTLIFACENDSIAPVNSSALPIYDSMSRNAKQFLEINGGSHSCA\n",
            "NSGNSNQALIGKKGVAWMKRFMDNDTRYSTFACENPNSTRVSDFRTANCS\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 8) Locate ProFam checkpoint_dir\n",
        "\n",
        "import pathlib, os\n",
        "\n",
        "repo = pathlib.Path(\"/content/profam_workshop/profam\").resolve()\n",
        "os.chdir(repo)\n",
        "\n",
        "candidates = []\n",
        "\n",
        "# Look inside the repository\n",
        "for p in pathlib.Path(\".\").rglob(\".hydra\"):\n",
        "    candidates.append(p.parent)\n",
        "\n",
        "# Look in Hugging Face cache\n",
        "hf_home = pathlib.Path(os.environ.get(\"HF_HOME\", \"/content/hf_cache\"))\n",
        "if hf_home.exists():\n",
        "    for p in hf_home.rglob(\".hydra\"):\n",
        "        candidates.append(p.parent)\n",
        "\n",
        "# De-duplicate\n",
        "uniq = []\n",
        "seen = set()\n",
        "for c in candidates:\n",
        "    c = c.resolve()\n",
        "    if c not in seen:\n",
        "        seen.add(c)\n",
        "        uniq.append(c)\n",
        "\n",
        "if not uniq:\n",
        "    raise RuntimeError(\n",
        "        \"Could not find a checkpoint directory containing '.hydra'. \"\n",
        "        \"Run the checkpoint download cell first.\"\n",
        "    )\n",
        "\n",
        "# Select the most recent checkpoint\n",
        "checkpoint_dir = sorted(uniq, key=lambda x: x.stat().st_mtime, reverse=True)[0]\n",
        "print(\"Using checkpoint_dir:\", checkpoint_dir)"
      ],
      "metadata": {
        "id": "K01hNFNM0Ejb",
        "outputId": "7313bd05-ac1a-47cc-ebe2-a41333c74792",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using checkpoint_dir: /content/profam_workshop/profam/model_checkpoints/profam-1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Sequences using ProFam-1\n",
        "\n",
        "In this section, we use **ProFam-1**, a protein family‚Äìaware generative model, to generate new protein sequences from a single input sequence.\n",
        "\n",
        "The model conditions on the input sequence and samples novel sequences that are consistent with the learned protein family constraints.\n",
        "\n",
        "**Notes for the workshop:**\n",
        "- The generation runs on **GPU** if available.\n",
        "- **Flash Attention is disabled** for compatibility with Google Colab.\n",
        "- Output sequences will be written as FASTA files in the `generated/` directory.\n",
        "\n"
      ],
      "metadata": {
        "id": "3nTvcavD0P9k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Runtime & Resource Notice**\n",
        ">\n",
        "> - Sequence generation may take **1‚Äì3 minutes** on a Google Colab GPU.\n",
        "> - The first run may be slightly slower due to **model weight loading**.\n",
        "> - If you see CUDA or cuDNN warnings, these are expected and can be ignored.\n",
        ">\n",
        "> If the notebook appears idle, please wait ‚Äî the model is still running."
      ],
      "metadata": {
        "id": "K0-MjOQO01-o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generation Parameters\n",
        "\n",
        "The sequence generation step uses probabilistic sampling. The key parameters are:\n",
        "\n",
        "| Parameter | Meaning |\n",
        "|---------|--------|\n",
        "| `temperature` | Controls randomness. Lower = more conservative, higher = more diverse |\n",
        "| `top_p` | Nucleus sampling threshold (keeps top probability mass) |\n",
        "| `num_samples` | Number of sequences generated per prompt |\n",
        "| `max_tokens` | Maximum total tokens generated |\n",
        "| `sampler` | `ensemble` uses multiple internal prompts for robustness |\n",
        "| `device` | `cuda` uses GPU if available |\n",
        "| `dtype` | `float16` reduces memory usage on GPU |\n",
        "| `attn_implementation` | `sdpa` is used instead of Flash Attention for Colab compatibility |\n",
        "\n",
        "**Tip:**  \n",
        "For more diversity, increase `temperature` (e.g. `1.2`).  \n",
        "For safer, more conservative sequences, decrease it (e.g. `0.8`)."
      ],
      "metadata": {
        "id": "59V1M2PH04E2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 9) Install MMseqs2 (required for --minimum_sequence_identity filtering)\n",
        "\n",
        "import os, pathlib\n",
        "\n",
        "WORK_DIR = pathlib.Path(\"/content/profam_workshop\").resolve()\n",
        "mmseqs_dir = WORK_DIR / \"mmseqs\"\n",
        "mmseqs_bin = mmseqs_dir / \"bin\" / \"mmseqs\"\n",
        "\n",
        "# Clean and install\n",
        "!rm -rf \"{mmseqs_dir}\"\n",
        "!mkdir -p \"{mmseqs_dir}\"\n",
        "!wget -q https://mmseqs.com/latest/mmseqs-linux-avx2.tar.gz -O /tmp/mmseqs.tar.gz\n",
        "!tar -xzf /tmp/mmseqs.tar.gz -C \"{mmseqs_dir}\" --strip-components=1\n",
        "!rm /tmp/mmseqs.tar.gz\n",
        "\n",
        "# Add to PATH\n",
        "os.environ[\"PATH\"] = f\"{mmseqs_dir}/bin:\" + os.environ[\"PATH\"]\n",
        "\n",
        "print(\"mmseqs binary:\", mmseqs_bin)\n",
        "!{mmseqs_bin} version"
      ],
      "metadata": {
        "id": "mgF_3pAUCdUQ",
        "outputId": "67d945b1-79d0-4973-f288-084aa9c63851",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mmseqs binary: /content/profam_workshop/mmseqs/bin/mmseqs\n",
            "01683a607f83878e95436632d73e1d7d9ae30955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 10) Device & dtype selection (GPU with safe fallback)\n",
        "\n",
        "import torch\n",
        "\n",
        "# Preferred defaults (workshop intent)\n",
        "PREFERRED_DEVICE = \"cuda\"\n",
        "PREFERRED_DTYPE  = \"float16\"\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = PREFERRED_DEVICE\n",
        "    dtype  = PREFERRED_DTYPE\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    print(f\"Using GPU: {gpu_name}\")\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "    dtype  = \"float32\"\n",
        "    print(\n",
        "        \"No NVIDIA GPU detected.\\n\"\n",
        "        \"Falling back to CPU (this will be slower, but functional).\"\n",
        "    )\n",
        "\n",
        "print(f\"device = {device}\")\n",
        "print(f\"dtype  = {dtype}\")"
      ],
      "metadata": {
        "id": "sPMylnhyqXsA",
        "outputId": "c0a8fcce-8baa-4af9-d724-a5407299d4fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU: Tesla T4\n",
            "device = cuda\n",
            "dtype  = float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 11) Generate sequences with ProFam-1\n",
        "\n",
        "import pathlib, os, shutil\n",
        "import torch\n",
        "\n",
        "# ---------------- User parameters ----------------\n",
        "num_sequences = 10  #@param {type:\"integer\", min:1, max:50, step:1}\n",
        "temperature   = 0.8  #@param {type:\"number\", min:0.5, max:1.5, step:0.1}\n",
        "\n",
        "max_tokens = 2048  #@param {type:\"integer\", min:256, max:8192, step:256}\n",
        "max_generated_length = 512  #@param {type:\"integer\", min:64, max:4096, step:64}\n",
        "\n",
        "min_seq_len_prop = 0.8   #@param {type:\"number\", min:0.5, max:1.0, step:0.05}\n",
        "max_len_mult     = 1.2   #@param {type:\"number\", min:1.0, max:2.0, step:0.1}\n",
        "min_seq_identity = 0.8   #@param {type:\"number\", min:0.0, max:0.9, step:0.05}\n",
        "\n",
        "# ---------------- Fixed workshop defaults ----------------\n",
        "top_p      = 0.95\n",
        "sampler    = \"ensemble\"\n",
        "attn_impl  = \"sdpa\"   # no flash-attn\n",
        "seed       = 1\n",
        "\n",
        "# ---------------- Auto device / dtype ----------------\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "    dtype  = \"float16\"\n",
        "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "    dtype  = \"float32\"\n",
        "    print(\"No GPU detected; using CPU (slower).\")\n",
        "\n",
        "# ---------------- Paths ----------------\n",
        "repo = pathlib.Path(\"/content/profam_workshop/profam\").resolve()\n",
        "os.chdir(repo)\n",
        "\n",
        "prompt_fa = repo / \"prompts.fasta\"\n",
        "save_dir  = repo / \"generated\"\n",
        "\n",
        "if not prompt_fa.exists():\n",
        "    raise FileNotFoundError(\"prompts.fasta not found. Run the prompt FASTA cell first.\")\n",
        "\n",
        "if \"checkpoint_dir\" not in globals():\n",
        "    raise RuntimeError(\"checkpoint_dir not set. Run the checkpoint discovery cell first.\")\n",
        "\n",
        "# Overwrite previous results\n",
        "if save_dir.exists():\n",
        "    shutil.rmtree(save_dir)\n",
        "save_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# ---------------- Run generation ----------------\n",
        "cmd = (\n",
        "    f\"python scripts/generate_sequences.py \"\n",
        "    f\"--checkpoint_dir '{checkpoint_dir}' \"\n",
        "    f\"--file_path '{prompt_fa}' \"\n",
        "    f\"--save_dir '{save_dir}' \"\n",
        "    f\"--sampler {sampler} \"\n",
        "    f\"--num_prompts_in_ensemble 1 \"\n",
        "    f\"--num_samples {num_sequences} \"\n",
        "    f\"--max_tokens {max_tokens} \"\n",
        "    f\"--max_generated_length {max_generated_length} \"\n",
        "    f\"--temperature {temperature} \"\n",
        "    f\"--top_p {top_p} \"\n",
        "    f\"--device {device} \"\n",
        "    f\"--dtype {dtype} \"\n",
        "    f\"--attn_implementation {attn_impl} \"\n",
        "    f\"--minimum_sequence_length_proportion {min_seq_len_prop} \"\n",
        "    f\"--max_sequence_length_multiplier {max_len_mult} \"\n",
        "    f\"--seed {seed}\"\n",
        ")\n",
        "\n",
        "# Only enable identity filter when mmseqs exists\n",
        "mmseqs_ok = shutil.which(\"mmseqs\") is not None\n",
        "if mmseqs_ok:\n",
        "    cmd += f\" --minimum_sequence_identity {min_seq_identity}\"\n",
        "else:\n",
        "    print(\"mmseqs not found in PATH; skipping --minimum_sequence_identity filtering.\")\n",
        "\n",
        "print(\"\\nCommand:\\n\", cmd, \"\\n\")\n",
        "!bash -lc \"{cmd}\"\n",
        "\n",
        "print(\"\\nGenerated files:\")\n",
        "!ls -lh \"{save_dir}\" | head -n 50"
      ],
      "metadata": {
        "id": "VOI6swA61QnR",
        "outputId": "7deadad6-41fa-4fdf-e75a-f56c6e6a4e1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU: Tesla T4\n",
            "\n",
            "Command:\n",
            " python scripts/generate_sequences.py --checkpoint_dir '/content/profam_workshop/profam/model_checkpoints/profam-1' --file_path '/content/profam_workshop/profam/prompts.fasta' --save_dir '/content/profam_workshop/profam/generated' --sampler ensemble --num_prompts_in_ensemble 1 --num_samples 10 --max_tokens 2048 --max_generated_length 512 --temperature 0.8 --top_p 0.95 --device cuda --dtype float16 --attn_implementation sdpa --minimum_sequence_length_proportion 0.8 --max_sequence_length_multiplier 1.2 --seed 1 --minimum_sequence_identity 0.8 \n",
            "\n",
            "/usr/local/lib/python3.12/dist-packages/lightning_utilities/core/imports.py:14: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "2026-02-19 10:25:27.605036: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1771496727.624499    3827 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1771496727.630595    3827 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1771496727.646053    3827 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771496727.646092    3827 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771496727.646098    3827 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771496727.646101    3827 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-19 10:25:27.650671: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Initialised Llama model, attention implementation:  sdpa\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['model.token_embedder.weight']\n",
            "Wrote 10 sequences -> /content/profam_workshop/profam/generated/prompts_generated_ensemble.fasta\n",
            "\n",
            "Generated files:\n",
            "total 4.0K\n",
            "-rw-r--r-- 1 root root 3.2K Feb 19 10:27 prompts_generated_ensemble.fasta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 12) Preview generated FASTA (first file)\n",
        "\n",
        "import pathlib\n",
        "\n",
        "repo = pathlib.Path(\"/content/profam_workshop/profam\").resolve()\n",
        "save_dir = repo / \"generated\"\n",
        "\n",
        "fasta_files = sorted(save_dir.glob(\"*.fa*\"))\n",
        "if not fasta_files:\n",
        "    raise RuntimeError(\"No FASTA files found in generated/. Run the generation cell first.\")\n",
        "\n",
        "fp = fasta_files[0]\n",
        "print(\"Showing:\", fp, \"\\n\")\n",
        "print(\"\\n\".join(fp.read_text().splitlines()[:120]))"
      ],
      "metadata": {
        "id": "gEH2TpMt1sVx",
        "outputId": "727b4b0f-88ce-4b76-f556-d80d13acd41a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Showing: /content/profam_workshop/profam/generated/prompts_generated_ensemble.fasta \n",
            "\n",
            ">prompts_sample_0_log_likelihood_-0.490\n",
            "MRRLTGASSALLAAALAAPALAQAPAPVAAAPAPRTAQAARERTAAGLTFPAGARLTEAAVLPDGPGPFPVRAYAVARPSGYGAGTVYYPADAGGPVGAIAIVPGYTARQSSIKWWGPRLASHGFVVVTIDTNSTLDQPSSRSAQQMAALRQVASLNGTSSSPIYGKVDTARIGVMGWSMGGGGSLISAANNPSLKAAAPQAPWDSSTNFSSVTVPTLIFACENDSIAPVNSSALPIYDSMSRNAKQFLEINGGSHSCANSGNSNQALIGKKGVAWMKRFMDNDTRYSTFACENPNSTRVSDFRTANCS\n",
            ">prompts_sample_1_log_likelihood_-0.151\n",
            "MVGGALLAAPLALAQADPYAKAPNPTAASLEASAGPFTVRSFTVSRPAGYGAGTVYYPTNAGGTVGAIAIVPGYTARQSSIKWWGPRLASHGFVVITIDTNSTLDQPSSRSSQQMAALRQVASLNGTSSSPIYGKVDTARMGVMGWSMGGGGSLISAANNPSLKAAAPQAPWDSSTNFSSVTVPTLIFACENDSIAPVNSSALPIYDSMSRNAKQFLEINGGSHSCANSGNSNQALIGKKGVAWMKRFMDNDTRYSTFACENPNSTRVSDFRTANCS\n",
            ">prompts_sample_2_log_likelihood_-0.792\n",
            "MRLALIFLSLLSLTACSTTKVLERDAADVRVLTATRLAGYPAGTVYYPVGPGGPVGAVVIVPGYSSSPSDISWWGERLAAHGFVVLTVSTNTTLDQPGSRATQQMRALQQVASANGTSSAPIYGHVDTARLGVMGWSMGGGGALIAASTNPSLKAAAPQAPWDSSTNFSSVTVPTLIFACENDTIAPVNSSALPIYDSMSRNAKQFLEINGGTHSCANSGNSNQALIGTKGVAWMKRFMDNDTRYTSFACDNPNSTRVSDFRTANCA\n",
            ">prompts_sample_3_log_likelihood_-0.511\n",
            "MKKLLLTLGLLVLIGGISFANAQELSDSSVETTDASIQTTLGPFTLTSYTVSRPQGFSAGTVYYPSNAGGVVGAIAIVPGYTANQASIKWWGPRLASHGFVVITIDTNSTLNQPSSRSAQQVAALRQVTSLNGSSSSPIYGKVDTARMGVMGWSMGGGGSLISAANNPSLKAAAPQAPWDSSTNFSSVTVPTLIFACENDSIAPVNSSALPIYDSMSRNAKQFLEINGGSHSCANSGNSNQALIGKKGVAWMKRFMDNDTRYSTFACENPNSTRVSDFRTANCS\n",
            ">prompts_sample_4_log_likelihood_-0.247\n",
            "MRTASALLAAAAATALAAGAAAAPAAAPGGAAPAAGPFTTRSFTVSRPAGYAAGTVYYPTNAGGTVGAIAIVPGYTARQSSIKWWGPRLASHGFVVITIDTNSTLDQPSSRSSQQMAALRQVASLNGTSSSPIYGKVDTARMGVMGWSMGGGGSLISAANNPSLKAAAPQAPWDSSTNFSSVTVPTLIFACENDSIAPVNSSALPIYDSMSRNAKQFLEINGGSHSCANSGNSNQALIGKKGVAWMKRFMDNDTRYSTFACENPNSTRVSDFRTANCS\n",
            ">prompts_sample_5_log_likelihood_-0.363\n",
            "MTLHSRVRALLAAVAGAAALGIAAPATAQSAPYASGTGGANLQASAGAFTVRSFTVNKPAGYGAGTVYYPTAAGGTVGAIAIVPGYTARQTSVKWWGPRLASHGFVVITIDTNSTLDQPSARSSQQMAALRQVASLNGTSSSPIYGKVDTARMGVMGWSMGGGGSLISAANNPSLKAAAPQAPWDSSTNFSSVTVPTLIFACENDSIAPVNSSALPIYDSMSRNAKQFLEINGGSHSCANSGNSNQALIGKKGVAWMKRFMDNDTRYSTFACENPNSTRVSDFRTANCS\n",
            ">prompts_sample_6_log_likelihood_-0.459\n",
            "MGHRRFGFRLRAAAASLLLGSSLLASLPAAAQGTPSSGTGAPAGASPAVTVRAFSTVRPGGFGAGTVYYPAAAGGAVGAIAIVPGYTARQSSIKWWGPRLASHGFVVVTIDTNSTLDQPSSRSSQQMAALRQVASLNGTSSSPIYGKVDTARMGVMGWSMGGGGSLISAANNPSLKAAAPQAPWDSSTNFSSVTVPTLIFACENDSIAPVNSSALPIYDSMSRNAKQFLEINGGSHSCANSGNSNQALIGKKGVAWMKRFMDNDTRYSTFACENPNSTRVSDFRTANCS\n",
            ">prompts_sample_7_log_likelihood_-0.399\n",
            "MKLLTFVLSLLLIAPASAAPPGSYAPGPVPGGAPLAAPGAPFTIRSFTVAKPGGYGPGTIYYPTNASGAVGAIAIVPGYTSRQSSIKWWGPRLASHGFVVITIDTNSTLDQPASRSSQQMAALRQVASLNGTASSPIYGKVDTARMGVMGWSMGGGGSLISAANNPSLKAAAPQAPWDSSTNFSSVTVPTLIFACENDSIAPVNSSALPIYDSMSRNAKQFLEINGGSHSCANSGNSNQALIGKKGVAWMKRFMDNDTRYSTFACENPNSTRVSDFRTANCS\n",
            ">prompts_sample_8_log_likelihood_-0.361\n",
            "MPRAAHWPRRIALVGLLLLPASAAAATPRAYDLGPNPTADTLAASAGPFTVRTFTIGRPSGFGPGTVYYPTTAGGTVGAIAIVPGYTARQSSIKWWGPRLASHGFVVITIDTNSTLDQPSSRSAQQMAALRQVATLNGTSSSPIYGKVDTARMGVMGWSMGGGGSLISAANNPSLKAAAPQAPWDSSTNFSSVTVPTLIFACENDSIAPVNSSALPIYDSMSRNAKQFLEINGGSHSCANSGNSNQALIGKKGVAWMKRFMDNDTRYSTFACENPNSTRVSDFRTANCS\n",
            ">prompts_sample_9_log_likelihood_-0.350\n",
            "MSALVLTGLLAACGGGGSSSSSGASTPASTPATTPTPTAPSVSVSAGPFAIRSVTTTRSSGYGAGSVYYPTNASGTVGAIAIVPGYTARQSSIKWWGPRLASHGFVVITIDTNSTLDQPSSRSSQQMAALRQVASLNGTSSSPIYGKVDTTRIGVMGWSMGGGGSLISAANNPSLKAAAPQAPWDSSTNFSSVTVPTLIFACENDSIAPVNSSALPIYDSMSRNAKQFLEINGGSHSCANSGNSNQALIGKKGVAWMKRFMDNDTRYSTFACENPNSTRVSDFRTANCS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 13) Rank generated sequences and pick the best candidate\n",
        "\n",
        "import pathlib, re\n",
        "import pandas as pd\n",
        "\n",
        "repo = pathlib.Path(\"/content/profam_workshop/profam\").resolve()\n",
        "prompt_fa = repo / \"prompts.fasta\"\n",
        "gen_dir = repo / \"generated\"\n",
        "out_best = repo / \"best_generated.fasta\"\n",
        "\n",
        "if not prompt_fa.exists():\n",
        "    raise FileNotFoundError(\"prompts.fasta not found.\")\n",
        "if not gen_dir.exists():\n",
        "    raise FileNotFoundError(\"generated/ directory not found. Run generation first.\")\n",
        "\n",
        "AA = set(\"ACDEFGHIKLMNPQRSTVWYBXZJUO\")\n",
        "\n",
        "def read_fasta(path: pathlib.Path):\n",
        "    records = []\n",
        "    name, seq = None, []\n",
        "    for line in path.read_text().splitlines():\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        if line.startswith(\">\"):\n",
        "            if name is not None:\n",
        "                records.append((name, \"\".join(seq)))\n",
        "            name = line[1:].strip()\n",
        "            seq = []\n",
        "        else:\n",
        "            seq.append(line)\n",
        "    if name is not None:\n",
        "        records.append((name, \"\".join(seq)))\n",
        "    return records\n",
        "\n",
        "def clean_seq(s: str) -> str:\n",
        "    s = re.sub(r\"\\s+\", \"\", s).upper()\n",
        "    return \"\".join(c for c in s if c.isalpha())\n",
        "\n",
        "def longest_run_fraction(s: str) -> float:\n",
        "    if not s:\n",
        "        return 0.0\n",
        "    best = 1\n",
        "    cur = 1\n",
        "    for i in range(1, len(s)):\n",
        "        if s[i] == s[i - 1]:\n",
        "            cur += 1\n",
        "            if cur > best:\n",
        "                best = cur\n",
        "        else:\n",
        "            cur = 1\n",
        "    return best / len(s)\n",
        "\n",
        "def kmer_low_complexity(s: str, k: int = 3) -> float:\n",
        "    if len(s) < k + 1:\n",
        "        return 0.0\n",
        "    kmers = [s[i:i + k] for i in range(len(s) - k + 1)]\n",
        "    return 1.0 - (len(set(kmers)) / len(kmers))\n",
        "\n",
        "def identity_to_prompt(g: str, p: str) -> float:\n",
        "    n = min(len(g), len(p))\n",
        "    if n == 0:\n",
        "        return 0.0\n",
        "    matches = sum(1 for i in range(n) if g[i] == p[i])\n",
        "    return matches / n\n",
        "\n",
        "prompt_records = read_fasta(prompt_fa)\n",
        "if not prompt_records:\n",
        "    raise RuntimeError(\"No FASTA records found in prompts.fasta.\")\n",
        "prompt_name, prompt_seq = prompt_records[0][0], clean_seq(prompt_records[0][1])\n",
        "\n",
        "rows = []\n",
        "for fp in sorted(gen_dir.glob(\"*.fa*\")):\n",
        "    for name, seq in read_fasta(fp):\n",
        "        seq = clean_seq(seq)\n",
        "        if not seq:\n",
        "            continue\n",
        "        if any(c not in AA for c in seq):\n",
        "            continue\n",
        "\n",
        "        rows.append(\n",
        "            {\n",
        "                \"file\": fp.name,\n",
        "                \"id\": name,\n",
        "                \"length\": len(seq),\n",
        "                \"len_ratio_to_prompt\": len(seq) / max(1, len(prompt_seq)),\n",
        "                \"prefix_identity_to_prompt\": identity_to_prompt(seq, prompt_seq),\n",
        "                \"longest_run_frac\": longest_run_fraction(seq),\n",
        "                \"kmer_low_complexity\": kmer_low_complexity(seq, k=3),\n",
        "                \"seq\": seq,\n",
        "            }\n",
        "        )\n",
        "\n",
        "if not rows:\n",
        "    raise RuntimeError(\"No generated sequences found/parsed in generated/.\")\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "\n",
        "target_min_id = 0.20\n",
        "target_max_id = 0.60\n",
        "\n",
        "def rank_score(r):\n",
        "    len_pen = abs(r[\"len_ratio_to_prompt\"] - 1.0)\n",
        "\n",
        "    idv = r[\"prefix_identity_to_prompt\"]\n",
        "    if idv < target_min_id:\n",
        "        id_pen = (target_min_id - idv) * 2.0\n",
        "    elif idv > target_max_id:\n",
        "        id_pen = (idv - target_max_id) * 2.0\n",
        "    else:\n",
        "        id_pen = 0.0\n",
        "\n",
        "    rep_pen = r[\"kmer_low_complexity\"] * 1.5 + r[\"longest_run_frac\"] * 2.0\n",
        "\n",
        "    return len_pen + id_pen + rep_pen\n",
        "\n",
        "df[\"rank_score\"] = df.apply(rank_score, axis=1)\n",
        "df_sorted = df.sort_values(\"rank_score\", ascending=True).reset_index(drop=True)\n",
        "\n",
        "display_cols = [\n",
        "    \"file\",\n",
        "    \"id\",\n",
        "    \"length\",\n",
        "    \"len_ratio_to_prompt\",\n",
        "    \"prefix_identity_to_prompt\",\n",
        "    \"kmer_low_complexity\",\n",
        "    \"longest_run_frac\",\n",
        "    \"rank_score\",\n",
        "]\n",
        "display(df_sorted[display_cols].head(15))\n",
        "\n",
        "best = df_sorted.iloc[0]\n",
        "best_id = best[\"id\"]\n",
        "best_seq = best[\"seq\"]\n",
        "\n",
        "wrapped = \"\\n\".join(best_seq[i:i + 60] for i in range(0, len(best_seq), 60))\n",
        "out_best.write_text(f\">{best_id}\\n{wrapped}\\n\")\n",
        "\n",
        "print(\"Recommended sequence:\")\n",
        "print(\"  ID:\", best_id)\n",
        "print(\"  Length:\", len(best_seq))\n",
        "print(\"  Score:\", float(best[\"rank_score\"]))\n",
        "print(\"  Saved:\", out_best)"
      ],
      "metadata": {
        "id": "m-pK0YQKBFk0",
        "outputId": "653cc791-503e-46e7-a98c-e6c3fd8a4ec4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                               file                                      id  \\\n",
              "0  prompts_generated_ensemble.fasta  prompts_sample_6_log_likelihood_-0.459   \n",
              "1  prompts_generated_ensemble.fasta  prompts_sample_5_log_likelihood_-0.363   \n",
              "2  prompts_generated_ensemble.fasta  prompts_sample_8_log_likelihood_-0.361   \n",
              "3  prompts_generated_ensemble.fasta  prompts_sample_9_log_likelihood_-0.350   \n",
              "4  prompts_generated_ensemble.fasta  prompts_sample_1_log_likelihood_-0.151   \n",
              "5  prompts_generated_ensemble.fasta  prompts_sample_3_log_likelihood_-0.511   \n",
              "6  prompts_generated_ensemble.fasta  prompts_sample_7_log_likelihood_-0.399   \n",
              "7  prompts_generated_ensemble.fasta  prompts_sample_0_log_likelihood_-0.490   \n",
              "8  prompts_generated_ensemble.fasta  prompts_sample_2_log_likelihood_-0.792   \n",
              "9  prompts_generated_ensemble.fasta  prompts_sample_4_log_likelihood_-0.247   \n",
              "\n",
              "   length  len_ratio_to_prompt  prefix_identity_to_prompt  \\\n",
              "0     289             0.996552                   0.128028   \n",
              "1     289             0.996552                   0.107266   \n",
              "2     289             0.996552                   0.107266   \n",
              "3     289             0.996552                   0.117647   \n",
              "4     277             0.955172                   0.090253   \n",
              "5     284             0.979310                   0.080986   \n",
              "6     282             0.972414                   0.078014   \n",
              "7     309             1.065517                   0.082759   \n",
              "8     267             0.920690                   0.067416   \n",
              "9     278             0.958621                   0.064748   \n",
              "\n",
              "   kmer_low_complexity  longest_run_frac  rank_score  \n",
              "0             0.069686          0.013841    0.279604  \n",
              "1             0.048780          0.013841    0.289768  \n",
              "2             0.052265          0.013841    0.294994  \n",
              "3             0.080139          0.017301    0.322965  \n",
              "4             0.043636          0.014440    0.358658  \n",
              "5             0.053191          0.014085    0.366674  \n",
              "6             0.057143          0.014184    0.385641  \n",
              "7             0.084691          0.012945    0.452926  \n",
              "8             0.060377          0.014981    0.465007  \n",
              "9             0.094203          0.017986    0.489158  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d12c8d01-c944-4d64-a472-b3a227711c76\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>id</th>\n",
              "      <th>length</th>\n",
              "      <th>len_ratio_to_prompt</th>\n",
              "      <th>prefix_identity_to_prompt</th>\n",
              "      <th>kmer_low_complexity</th>\n",
              "      <th>longest_run_frac</th>\n",
              "      <th>rank_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>prompts_generated_ensemble.fasta</td>\n",
              "      <td>prompts_sample_6_log_likelihood_-0.459</td>\n",
              "      <td>289</td>\n",
              "      <td>0.996552</td>\n",
              "      <td>0.128028</td>\n",
              "      <td>0.069686</td>\n",
              "      <td>0.013841</td>\n",
              "      <td>0.279604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>prompts_generated_ensemble.fasta</td>\n",
              "      <td>prompts_sample_5_log_likelihood_-0.363</td>\n",
              "      <td>289</td>\n",
              "      <td>0.996552</td>\n",
              "      <td>0.107266</td>\n",
              "      <td>0.048780</td>\n",
              "      <td>0.013841</td>\n",
              "      <td>0.289768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>prompts_generated_ensemble.fasta</td>\n",
              "      <td>prompts_sample_8_log_likelihood_-0.361</td>\n",
              "      <td>289</td>\n",
              "      <td>0.996552</td>\n",
              "      <td>0.107266</td>\n",
              "      <td>0.052265</td>\n",
              "      <td>0.013841</td>\n",
              "      <td>0.294994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>prompts_generated_ensemble.fasta</td>\n",
              "      <td>prompts_sample_9_log_likelihood_-0.350</td>\n",
              "      <td>289</td>\n",
              "      <td>0.996552</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.080139</td>\n",
              "      <td>0.017301</td>\n",
              "      <td>0.322965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>prompts_generated_ensemble.fasta</td>\n",
              "      <td>prompts_sample_1_log_likelihood_-0.151</td>\n",
              "      <td>277</td>\n",
              "      <td>0.955172</td>\n",
              "      <td>0.090253</td>\n",
              "      <td>0.043636</td>\n",
              "      <td>0.014440</td>\n",
              "      <td>0.358658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>prompts_generated_ensemble.fasta</td>\n",
              "      <td>prompts_sample_3_log_likelihood_-0.511</td>\n",
              "      <td>284</td>\n",
              "      <td>0.979310</td>\n",
              "      <td>0.080986</td>\n",
              "      <td>0.053191</td>\n",
              "      <td>0.014085</td>\n",
              "      <td>0.366674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>prompts_generated_ensemble.fasta</td>\n",
              "      <td>prompts_sample_7_log_likelihood_-0.399</td>\n",
              "      <td>282</td>\n",
              "      <td>0.972414</td>\n",
              "      <td>0.078014</td>\n",
              "      <td>0.057143</td>\n",
              "      <td>0.014184</td>\n",
              "      <td>0.385641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>prompts_generated_ensemble.fasta</td>\n",
              "      <td>prompts_sample_0_log_likelihood_-0.490</td>\n",
              "      <td>309</td>\n",
              "      <td>1.065517</td>\n",
              "      <td>0.082759</td>\n",
              "      <td>0.084691</td>\n",
              "      <td>0.012945</td>\n",
              "      <td>0.452926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>prompts_generated_ensemble.fasta</td>\n",
              "      <td>prompts_sample_2_log_likelihood_-0.792</td>\n",
              "      <td>267</td>\n",
              "      <td>0.920690</td>\n",
              "      <td>0.067416</td>\n",
              "      <td>0.060377</td>\n",
              "      <td>0.014981</td>\n",
              "      <td>0.465007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>prompts_generated_ensemble.fasta</td>\n",
              "      <td>prompts_sample_4_log_likelihood_-0.247</td>\n",
              "      <td>278</td>\n",
              "      <td>0.958621</td>\n",
              "      <td>0.064748</td>\n",
              "      <td>0.094203</td>\n",
              "      <td>0.017986</td>\n",
              "      <td>0.489158</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d12c8d01-c944-4d64-a472-b3a227711c76')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d12c8d01-c944-4d64-a472-b3a227711c76 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d12c8d01-c944-4d64-a472-b3a227711c76');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"  Saved:\\\", out_best)\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"file\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"prompts_generated_ensemble.fasta\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"prompts_sample_2_log_likelihood_-0.792\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 267,\n        \"max\": 309,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          289\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"len_ratio_to_prompt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03788049576375292,\n        \"min\": 0.9206896551724137,\n        \"max\": 1.0655172413793104,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.996551724137931\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prefix_identity_to_prompt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02153134309825073,\n        \"min\": 0.06474820143884892,\n        \"max\": 0.12802768166089964,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.06741573033707865\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"kmer_low_complexity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01697197420374621,\n        \"min\": 0.043636363636363584,\n        \"max\": 0.09420289855072461,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.060377358490566024\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"longest_run_frac\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0016202410412753847,\n        \"min\": 0.012944983818770227,\n        \"max\": 0.017985611510791366,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.01730103806228374\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rank_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.076688417225737,\n        \"min\": 0.2796041901646623,\n        \"max\": 0.4891584783147994,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.46500746870575743\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommended sequence:\n",
            "  ID: prompts_sample_6_log_likelihood_-0.459\n",
            "  Length: 289\n",
            "  Score: 0.2796041901646623\n",
            "  Saved: /content/profam_workshop/profam/best_generated.fasta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/profam_workshop/profam/best_generated.fasta"
      ],
      "metadata": {
        "id": "bGT6Gx3pDTUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Once you reach this step, kill the next cell. Select the best ranked sequence from the previous cell and go to Colabfold and start modelling your sequence with AF2. Once done, retrieve the AFDB mmCIF structure of isPETase from https://www.alphafold.ebi.ac.uk/entry/AF-A0A0K8P6T7-F1 , run the next cell and upload both structures. Continue the notebook from the next cell. WARNING: THIS WILL DISCONNECT YOUR NOTEBOOK. For the sake of this workshop you can choose to re-run the notebook from the top and upload the structures, or skip the next two cells."
      ],
      "metadata": {
        "id": "7QiMyq9RCilf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 14) Upload two structures for TM-score and visualisation\n",
        "\n",
        "from google.colab import files\n",
        "from pathlib import Path\n",
        "\n",
        "UPLOAD_DIR = Path(\"/content/tmalign_uploads\")\n",
        "UPLOAD_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "def upload_one(label):\n",
        "    print(f\"\\nUpload {label} (PDB .pdb/.ent or mmCIF .cif/.mmcif)\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if len(uploaded) != 1:\n",
        "        raise RuntimeError(\n",
        "            f\"{label}: Please upload exactly one file (got {len(uploaded)}). \"\n",
        "            \"Re-run the cell.\"\n",
        "        )\n",
        "\n",
        "    name, data = next(iter(uploaded.items()))\n",
        "    dst = UPLOAD_DIR / name\n",
        "\n",
        "    with open(dst, \"wb\") as f:\n",
        "        f.write(data)\n",
        "\n",
        "    print(f\"{label} saved to: {dst}\")\n",
        "    return str(dst)\n",
        "\n",
        "# Upload structure A\n",
        "struct_a = upload_one(\"Structure A (e.g. ProFam-generated model)\")\n",
        "\n",
        "# Upload structure B\n",
        "struct_b = upload_one(\"Structure B (e.g. AFDB or reference structure)\")\n",
        "\n",
        "print(\"\\nStructures ready for TM-score:\")\n",
        "print(\"  Structure A:\", struct_a)\n",
        "print(\"  Structure B:\", struct_b)\n",
        "print(\"\\nRun the TM-score alignment cell next.\")"
      ],
      "metadata": {
        "id": "0tSjFaKYHzzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 15) TM-align: align A vs B, report TM-score, and visualise superposition (single output)\n",
        "\n",
        "import re, subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "SHOW_3DMOL = False  #@param {type:\"boolean\"}  # If True, shows 3Dmol output before NGLView\n",
        "\n",
        "# --- Inputs from upload cells ------------------------------------------------\n",
        "if \"struct_a\" not in globals() or \"struct_b\" not in globals():\n",
        "    raise RuntimeError(\"struct_a / struct_b not set. Run the upload cell first.\")\n",
        "\n",
        "struct_a = str(struct_a)\n",
        "struct_b = str(struct_b)\n",
        "\n",
        "chain_a = \"\"  #@param {type:\"string\"}  # leave blank = first chain\n",
        "chain_b = \"\"  #@param {type:\"string\"}  # leave blank = first chain\n",
        "\n",
        "WORK_DIR = Path(\"/content/tmalign_work\").resolve()\n",
        "WORK_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Install deps (quiet)\n",
        "!pip -q install gemmi nglview\n",
        "if SHOW_3DMOL:\n",
        "    !pip -q install py3Dmol\n",
        "\n",
        "# Enable widget manager for NGLView in Colab\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "import gemmi\n",
        "import nglview as nv\n",
        "\n",
        "def ensure_tmalign(bin_path: Path) -> Path:\n",
        "    if bin_path.exists():\n",
        "        return bin_path\n",
        "    bin_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    url = \"https://zhanggroup.org/TM-align/TMalign\"\n",
        "    subprocess.run([\"bash\", \"-lc\", f\"wget -q '{url}' -O '{bin_path}'\"], check=True)\n",
        "    subprocess.run([\"bash\", \"-lc\", f\"chmod +x '{bin_path}'\"], check=True)\n",
        "    return bin_path\n",
        "\n",
        "TMALIGN = ensure_tmalign(WORK_DIR / \"bin\" / \"TMalign\")\n",
        "\n",
        "def first_chain_id(path: str) -> str:\n",
        "    st = gemmi.read_structure(path)\n",
        "    for model in st:\n",
        "        for ch in model:\n",
        "            return ch.name\n",
        "    return \"\"\n",
        "\n",
        "def to_pdb(in_path: str, out_path: Path, chain_id: str = \"\") -> Path:\n",
        "    st = gemmi.read_structure(str(in_path))\n",
        "    if chain_id.strip():\n",
        "        keep = chain_id.strip()\n",
        "        for model in st:\n",
        "            for ch in list(model):\n",
        "                if ch.name != keep:\n",
        "                    model.remove_chain(ch.name)\n",
        "        st.remove_empty_chains()\n",
        "    st.write_pdb(str(out_path))\n",
        "    return out_path\n",
        "\n",
        "# Choose default chains if blank\n",
        "if chain_a.strip() == \"\":\n",
        "    chain_a = first_chain_id(struct_a)\n",
        "if chain_b.strip() == \"\":\n",
        "    chain_b = first_chain_id(struct_b)\n",
        "\n",
        "# Prepare inputs\n",
        "pdb_a = WORK_DIR / \"A.pdb\"\n",
        "pdb_b = WORK_DIR / \"B.pdb\"\n",
        "to_pdb(struct_a, pdb_a, chain_a)\n",
        "to_pdb(struct_b, pdb_b, chain_b)\n",
        "\n",
        "# --- Run TM-align with matrix output -----------------------------------------\n",
        "matrix_file = WORK_DIR / \"tmalign_matrix.txt\"\n",
        "if matrix_file.exists():\n",
        "    matrix_file.unlink()\n",
        "\n",
        "res = subprocess.run(\n",
        "    [str(TMALIGN), str(pdb_a), str(pdb_b), \"-m\", str(matrix_file)],\n",
        "    capture_output=True, text=True\n",
        ")\n",
        "out = (res.stdout or \"\") + \"\\n\" + (res.stderr or \"\")\n",
        "if res.returncode != 0:\n",
        "    print(out)\n",
        "    raise RuntimeError(f\"TM-align failed with exit code {res.returncode}\")\n",
        "\n",
        "# --- Parse summary ------------------------------------------------------------\n",
        "tm_scores = [float(x) for x in re.findall(r\"TM-score=\\s*([0-9]*\\.[0-9]+)\", out)]\n",
        "rmsd_m = re.search(r\"RMSD=\\s*([0-9]*\\.[0-9]+)\", out)\n",
        "aln_m  = re.search(r\"Aligned length=\\s*(\\d+)\", out)\n",
        "\n",
        "print(\"TM-align summary\")\n",
        "print(\"  A:\", Path(struct_a).name, f\"(chain {chain_a})\")\n",
        "print(\"  B:\", Path(struct_b).name, f\"(chain {chain_b})\")\n",
        "if aln_m:\n",
        "    print(f\"  Aligned length: {int(aln_m.group(1))}\")\n",
        "if rmsd_m:\n",
        "    print(f\"  RMSD: {float(rmsd_m.group(1)):.3f}\")\n",
        "if tm_scores:\n",
        "    if len(tm_scores) >= 2:\n",
        "        print(f\"  TM-score (norm by A length): {tm_scores[0]:.5f}\")\n",
        "        print(f\"  TM-score (norm by B length): {tm_scores[1]:.5f}\")\n",
        "        print(f\"  TM-score (max): {max(tm_scores[0], tm_scores[1]):.5f}\")\n",
        "    else:\n",
        "        print(f\"  TM-score: {tm_scores[0]:.5f}\")\n",
        "print()\n",
        "\n",
        "# --- Robust parse of 3x4 matrix from -m file ---------------------------------\n",
        "if not matrix_file.exists() or matrix_file.stat().st_size == 0:\n",
        "    raise RuntimeError(\"TM-align did not create a matrix file. Something went wrong with -m.\")\n",
        "\n",
        "lines = [ln.strip() for ln in matrix_file.read_text().splitlines() if ln.strip()]\n",
        "\n",
        "rows = {}\n",
        "for ln in lines:\n",
        "    parts = ln.split()\n",
        "    if len(parts) >= 5 and parts[0] in (\"1\", \"2\", \"3\"):\n",
        "        m = int(parts[0])\n",
        "        rows[m] = [float(parts[1]), float(parts[2]), float(parts[3]), float(parts[4])]\n",
        "\n",
        "if not all(k in rows for k in (1, 2, 3)):\n",
        "    raise RuntimeError(\n",
        "        \"Could not parse the 3 rotation-matrix rows from TM-align -m output.\\n\"\n",
        "        \"First 30 non-empty lines:\\n\" + \"\\n\".join(lines[:30])\n",
        "    )\n",
        "\n",
        "t = [rows[1][0], rows[2][0], rows[3][0]]\n",
        "U = [\n",
        "    [rows[1][1], rows[1][2], rows[1][3]],\n",
        "    [rows[2][1], rows[2][2], rows[2][3]],\n",
        "    [rows[3][1], rows[3][2], rows[3][3]],\n",
        "]\n",
        "\n",
        "# TM-align: X2 = t + U * x1  (Chain_1 -> Chain_2)\n",
        "# We want to move B onto A => apply inverse transform to B:\n",
        "UT = [\n",
        "    [U[0][0], U[1][0], U[2][0]],\n",
        "    [U[0][1], U[1][1], U[2][1]],\n",
        "    [U[0][2], U[1][2], U[2][2]],\n",
        "]\n",
        "t_inv = [\n",
        "    -(UT[0][0]*t[0] + UT[0][1]*t[1] + UT[0][2]*t[2]),\n",
        "    -(UT[1][0]*t[0] + UT[1][1]*t[1] + UT[1][2]*t[2]),\n",
        "    -(UT[2][0]*t[0] + UT[2][1]*t[1] + UT[2][2]*t[2]),\n",
        "]\n",
        "\n",
        "M_inv = [\n",
        "    UT[0][0], UT[0][1], UT[0][2], t_inv[0],\n",
        "    UT[1][0], UT[1][1], UT[1][2], t_inv[1],\n",
        "    UT[2][0], UT[2][1], UT[2][2], t_inv[2],\n",
        "    0,        0,        0,        1\n",
        "]\n",
        "\n",
        "# --- Write B superposed onto A (for NGLView) ---------------------------------\n",
        "B_SUP = WORK_DIR / \"B_superposed.pdb\"\n",
        "\n",
        "def apply_transform_to_structure(in_pdb: Path, out_pdb: Path, M):\n",
        "    st = gemmi.read_structure(str(in_pdb))\n",
        "    r11,r12,r13,t1, r21,r22,r23,t2, r31,r32,r33,t3, _,_,_,_ = M\n",
        "    for model in st:\n",
        "        for chain in model:\n",
        "            for res in chain:\n",
        "                for atom in res:\n",
        "                    x,y,z = atom.pos.x, atom.pos.y, atom.pos.z\n",
        "                    X = t1 + r11*x + r12*y + r13*z\n",
        "                    Y = t2 + r21*x + r22*y + r23*z\n",
        "                    Z = t3 + r31*x + r32*y + r33*z\n",
        "                    atom.pos = gemmi.Position(X, Y, Z)\n",
        "    st.write_pdb(str(out_pdb))\n",
        "\n",
        "apply_transform_to_structure(pdb_b, B_SUP, M_inv)\n",
        "\n",
        "# --- Optional: 3Dmol (only if requested) -------------------------------------\n",
        "if SHOW_3DMOL:\n",
        "    import py3Dmol\n",
        "    v3 = py3Dmol.view(width=900, height=520)\n",
        "    v3.addModel(pdb_a.read_text(), \"pdb\")\n",
        "    v3.addModel(pdb_b.read_text(), \"pdb\")\n",
        "    v3.setTransform({\"model\": 1}, M_inv)\n",
        "    v3.setStyle({\"model\": 0}, {\"cartoon\": {\"color\": \"dodgerblue\"}})\n",
        "    v3.setStyle({\"model\": 1}, {\"cartoon\": {\"color\": \"tomato\", \"opacity\": 0.70}})\n",
        "    v3.zoomTo()\n",
        "    v3  # render as output (no .show())\n",
        "\n",
        "# Superposition viewer (NGLView, force uniform colors; defeat rainbow defaults)\n",
        "\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "!pip -q install nglview gemmi\n",
        "\n",
        "import nglview as nv\n",
        "from pathlib import Path\n",
        "\n",
        "WORK_DIR = Path(\"/content/tmalign_work\").resolve()\n",
        "pdb_a = WORK_DIR / \"A.pdb\"\n",
        "b_sup = WORK_DIR / \"B_superposed.pdb\"\n",
        "\n",
        "if not pdb_a.exists():\n",
        "    raise FileNotFoundError(pdb_a)\n",
        "if not b_sup.exists():\n",
        "    raise FileNotFoundError(b_sup)\n",
        "\n",
        "view = nv.NGLWidget()\n",
        "\n",
        "# Add components\n",
        "compA = view.add_component(str(pdb_a))\n",
        "compB = view.add_component(str(b_sup))\n",
        "\n",
        "compA.clear_representations()\n",
        "compB.clear_representations()\n",
        "\n",
        "\n",
        "compA.add_cartoon(colorScheme=\"uniform\", color=\"red\")\n",
        "compB.add_cartoon(colorScheme=\"uniform\", color=\"blue\", opacity=0.7)\n",
        "\n",
        "view.center()\n",
        "view"
      ],
      "metadata": {
        "id": "hgBnxxixT-3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variant Scoring with ProFam-1 using ProteinGym DMS Data\n",
        "\n",
        "In this section, we demonstrate ProFam-1‚Äôs **variant scoring** capability using experimental Deep Mutational Scanning (DMS) data from the ProteinGym benchmark.\n",
        "\n",
        "Unlike sequence generation, variant scoring evaluates how well the model ranks mutated protein sequences relative to experimentally measured functional effects.\n",
        "\n",
        "### Concept\n",
        "\n",
        "ProFam scoring requires two inputs:\n",
        "\n",
        "- **conditioning_fasta**  \n",
        "  A sequence or multiple sequences representing the functional family context.  \n",
        "  This can be:\n",
        "  - The wild-type (WT) sequence only\n",
        "  - A small set of homologous functional variants\n",
        "  - A full MSA (optional, but improves family conditioning)\n",
        "\n",
        "- **candidates_file**  \n",
        "  A FASTA file containing mutated variants to score and rank.\n",
        "\n",
        "### Workflow Overview\n",
        "\n",
        "1. Download a ProteinGym DMS dataset.\n",
        "2. Extract the UniProt identifier from the filename.\n",
        "3. Retrieve the wild-type sequence from UniProt.\n",
        "4. Create:\n",
        "   - `conditioning.fasta` (WT or small family set)\n",
        "   - `candidates.fasta` (mutant sequences from DMS)\n",
        "5. Run `score_sequences.py`.\n",
        "6. Compare ProFam scores with experimental DMS measurements (e.g., Spearman correlation).\n",
        "\n",
        "This demonstrates how ProFam can be used to rank variants by predicted fitness and assess how well model likelihood correlates with real experimental data."
      ],
      "metadata": {
        "id": "zML1IlGJH2aA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download and extract ProteinGym DMS dataset (v1.3)\n",
        "\n",
        "import pathlib\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "BASE_DIR = pathlib.Path(\"/content/proteingym\").resolve()\n",
        "BASE_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "zip_path = BASE_DIR / \"DMS_ProteinGym_substitutions.zip\"\n",
        "url = \"https://marks.hms.harvard.edu/proteingym/ProteinGym_v1.3/DMS_ProteinGym_substitutions.zip\"\n",
        "\n",
        "# --- Download only if not already present -----------------------------------\n",
        "if not zip_path.exists():\n",
        "    print(\"Downloading ProteinGym dataset...\")\n",
        "    response = requests.get(url, stream=True)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    with open(zip_path, \"wb\") as f:\n",
        "        for chunk in response.iter_content(chunk_size=8192):\n",
        "            f.write(chunk)\n",
        "\n",
        "    print(\"Download complete:\", zip_path)\n",
        "else:\n",
        "    print(\"Zip file already exists:\", zip_path)\n",
        "\n",
        "# --- Extract only if CSVs not already extracted ------------------------------\n",
        "csv_files = list(BASE_DIR.rglob(\"*.csv\"))\n",
        "\n",
        "if not csv_files:\n",
        "    print(\"Extracting archive...\")\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as z:\n",
        "        z.extractall(BASE_DIR)\n",
        "    print(\"Extraction complete.\")\n",
        "else:\n",
        "    print(\"CSV files already extracted.\")\n",
        "\n",
        "# --- List available DMS datasets --------------------------------------------\n",
        "print(\"\\nAvailable DMS CSV files:\")\n",
        "for p in sorted(BASE_DIR.rglob(\"*.csv\"))[:20]:\n",
        "    print(\" \", p.name)\n",
        "\n",
        "print(\"\\nTotal CSV files found:\", len(list(BASE_DIR.rglob(\"*.csv\"))))"
      ],
      "metadata": {
        "id": "20y1QxL0dKPZ",
        "outputId": "1a9e36d5-285b-4029-b8cb-d9749a9b3335",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ProteinGym dataset...\n",
            "Download complete: /content/proteingym/DMS_ProteinGym_substitutions.zip\n",
            "Extracting archive...\n",
            "Extraction complete.\n",
            "\n",
            "Available DMS CSV files:\n",
            "  A0A140D2T1_ZIKV_Sourisseau_2019.csv\n",
            "  A0A192B1T2_9HIV1_Haddox_2018.csv\n",
            "  A0A1I9GEU1_NEIME_Kennouche_2019.csv\n",
            "  A0A247D711_LISMN_Stadelmann_2021.csv\n",
            "  A0A2Z5U3Z0_9INFA_Doud_2016.csv\n",
            "  A0A2Z5U3Z0_9INFA_Wu_2014.csv\n",
            "  A4D664_9INFA_Soh_2019.csv\n",
            "  A4GRB6_PSEAI_Chen_2020.csv\n",
            "  A4_HUMAN_Seuma_2022.csv\n",
            "  AACC1_PSEAI_Dandage_2018.csv\n",
            "  ACE2_HUMAN_Chan_2020.csv\n",
            "  ADRB2_HUMAN_Jones_2020.csv\n",
            "  AICDA_HUMAN_Gajula_2014_3cycles.csv\n",
            "  AMFR_HUMAN_Tsuboyama_2023_4G3O.csv\n",
            "  AMIE_PSEAE_Wrenbeck_2017.csv\n",
            "  ANCSZ_Hobbs_2022.csv\n",
            "  ARGR_ECOLI_Tsuboyama_2023_1AOY.csv\n",
            "  B2L11_HUMAN_Dutta_2010_binding-Mcl-1.csv\n",
            "  BBC1_YEAST_Tsuboyama_2023_1TG0.csv\n",
            "  BCHB_CHLTE_Tsuboyama_2023_2KRU.csv\n",
            "\n",
            "Total CSV files found: 217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 16) Select a ProteinGym DMS dataset\n",
        "\n",
        "import pathlib\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "BASE_DIR = pathlib.Path(\"/content/proteingym\").resolve()\n",
        "\n",
        "csv_files = sorted(BASE_DIR.rglob(\"*.csv\"))\n",
        "\n",
        "if not csv_files:\n",
        "    raise RuntimeError(\"No CSV files found. Run the download cell first.\")\n",
        "\n",
        "file_dict = {p.name: str(p) for p in csv_files}\n",
        "\n",
        "dropdown = widgets.Dropdown(\n",
        "    options=sorted(file_dict.keys()),\n",
        "    description=\"Dataset:\",\n",
        "    layout=widgets.Layout(width=\"70%\"),\n",
        ")\n",
        "\n",
        "output = widgets.Output()\n",
        "\n",
        "selected_file_path = file_dict[dropdown.value]\n",
        "\n",
        "def on_change(change):\n",
        "    global selected_file_path\n",
        "    selected_file_path = file_dict[change[\"new\"]]\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        print(\"Selected dataset:\")\n",
        "        print(selected_file_path)\n",
        "\n",
        "dropdown.observe(on_change, names=\"value\")\n",
        "\n",
        "display(dropdown, output)\n",
        "\n",
        "# Initial display\n",
        "with output:\n",
        "    print(\"Selected dataset:\")\n",
        "    print(selected_file_path)"
      ],
      "metadata": {
        "id": "jSNeYUc3EA2E",
        "outputId": "16a60014-3548-479b-cfce-ed881aed79ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "ceb076075177442eb3571da4719d4856",
            "3f1ce42fef2d49d79060bb9ce4c8c31d",
            "82d4d01f086c4cd2a9b456e6f01228f4",
            "ec67f28adfa347019114ab0fa73a295c",
            "38856fa5138e41529dc948a22e325f4e"
          ]
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Dataset:', layout=Layout(width='70%'), options=('A0A140D2T1_ZIKV_Sourisseau_2019.csv', '‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ceb076075177442eb3571da4719d4856"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec67f28adfa347019114ab0fa73a295c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 17) Inspect selected DMS dataset\n",
        "\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "if \"selected_file_path\" not in globals():\n",
        "    raise RuntimeError(\"selected_file_path not defined. Run the dropdown cell first.\")\n",
        "\n",
        "dms_file = Path(selected_file_path)\n",
        "print(\"Loading:\", dms_file.name)\n",
        "\n",
        "df = pd.read_csv(dms_file)\n",
        "\n",
        "print(\"\\nShape:\", df.shape)\n",
        "print(\"\\nColumns:\")\n",
        "for c in df.columns:\n",
        "    print(\" \", c)\n",
        "\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "display(df.head())\n",
        "\n",
        "print(\"\\nExample mutation strings:\")\n",
        "if \"mutant\" in df.columns:\n",
        "    print(df[\"mutant\"].head(10).tolist())\n",
        "elif \"mutation\" in df.columns:\n",
        "    print(df[\"mutation\"].head(10).tolist())\n",
        "else:\n",
        "    print(\"Could not automatically find mutation column ‚Äî check column names above.\")"
      ],
      "metadata": {
        "id": "6zLga819JZBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 18) Retrieve WT sequence from UniProt (conditioning_fasta)\n",
        "\n",
        "import requests\n",
        "import pathlib\n",
        "import re\n",
        "import os\n",
        "\n",
        "# ---- Ensure repo directory exists -------------------------------------------\n",
        "repo = pathlib.Path(\"/content/profam_workshop/profam\").resolve()\n",
        "\n",
        "if not repo.exists():\n",
        "    raise RuntimeError(\n",
        "        f\"ProFam repo not found at {repo}.\\n\"\n",
        "        \"Run the clone/install cells first.\"\n",
        "    )\n",
        "\n",
        "conditioning_fasta = repo / \"conditioning.fasta\"\n",
        "\n",
        "# ---- Check UniProt ID --------------------------------------------------------\n",
        "if \"selected_uniprot_id\" not in globals() or selected_uniprot_id is None:\n",
        "    raise RuntimeError(\"No UniProt ID found. Run the DMS selection cell first.\")\n",
        "\n",
        "print(\"Retrieving WT sequence for:\", selected_uniprot_id)\n",
        "\n",
        "# ---- Query UniProt REST API --------------------------------------------------\n",
        "query_url = (\n",
        "    \"https://rest.uniprot.org/uniprotkb/search\"\n",
        "    f\"?query={selected_uniprot_id}\"\n",
        "    \"&format=fasta&size=1\"\n",
        ")\n",
        "\n",
        "response = requests.get(query_url)\n",
        "\n",
        "if response.status_code != 200:\n",
        "    raise RuntimeError(f\"UniProt request failed: {response.status_code}\")\n",
        "\n",
        "fasta_text = response.text.strip()\n",
        "\n",
        "if not fasta_text.startswith(\">\"):\n",
        "    raise RuntimeError(\n",
        "        f\"Failed to retrieve valid FASTA for {selected_uniprot_id}.\\n\"\n",
        "        \"Check that the mnemonic exists in UniProt.\"\n",
        "    )\n",
        "\n",
        "# ---- Write conditioning FASTA ------------------------------------------------\n",
        "conditioning_fasta.write_text(fasta_text + \"\\n\")\n",
        "\n",
        "print(\"Saved WT FASTA to:\", conditioning_fasta)\n",
        "\n",
        "# ---- Extract WT sequence for later use --------------------------------------\n",
        "lines = fasta_text.splitlines()\n",
        "wt_sequence = \"\".join([ln.strip() for ln in lines if not ln.startswith(\">\")])\n",
        "wt_sequence = re.sub(r\"\\s+\", \"\", wt_sequence)\n",
        "\n",
        "print(\"\\nWT length:\", len(wt_sequence))\n",
        "print(\"First 60 aa:\")\n",
        "print(wt_sequence[:60])"
      ],
      "metadata": {
        "id": "EQpt2H4cIT_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 19) Build candidates.fasta from selected DMS dataset (cap at 500 variants)\n",
        "\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "MAX_VARIANTS = 500\n",
        "\n",
        "if \"selected_file_path\" not in globals():\n",
        "    raise RuntimeError(\"selected_file_path not defined. Run the dropdown cell first.\")\n",
        "\n",
        "repo = Path(\"/content/profam_workshop/profam\").resolve()\n",
        "candidates_fasta = repo / \"candidates.fasta\"\n",
        "\n",
        "df = pd.read_csv(selected_file_path)\n",
        "\n",
        "if \"mutated_sequence\" not in df.columns:\n",
        "    raise RuntimeError(\"Expected column 'mutated_sequence' not found.\")\n",
        "\n",
        "print(\"Total variants in dataset:\", len(df))\n",
        "\n",
        "# Optional: shuffle before selecting (avoids ordering bias)\n",
        "df = df.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Cap to MAX_VARIANTS\n",
        "df_subset = df.head(MAX_VARIANTS)\n",
        "\n",
        "print(\"Variants used for scoring:\", len(df_subset))\n",
        "\n",
        "with open(candidates_fasta, \"w\") as f:\n",
        "    for i, row in df_subset.iterrows():\n",
        "        seq = str(row[\"mutated_sequence\"]).strip().upper()\n",
        "        f.write(f\">variant_{i}\\n{seq}\\n\")\n",
        "\n",
        "print(\"Saved:\", candidates_fasta)"
      ],
      "metadata": {
        "id": "ZU629W75JGRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 20) Score DMS variants with ProFam\n",
        "\n",
        "import torch\n",
        "import pathlib\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "repo = pathlib.Path(\"/content/profam_workshop/profam\").resolve()\n",
        "os.chdir(repo)\n",
        "\n",
        "conditioning_fasta = repo / \"conditioning.fasta\"\n",
        "candidates_fasta   = repo / \"candidates.fasta\"\n",
        "output_dir         = repo / \"scoring\"\n",
        "\n",
        "if not conditioning_fasta.exists():\n",
        "    raise FileNotFoundError(\"conditioning.fasta not found.\")\n",
        "if not candidates_fasta.exists():\n",
        "    raise FileNotFoundError(\"candidates.fasta not found.\")\n",
        "if \"checkpoint_dir\" not in globals():\n",
        "    raise RuntimeError(\"checkpoint_dir not defined. Run checkpoint discovery cell first.\")\n",
        "\n",
        "# Auto device selection\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "    dtype  = \"float16\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "    dtype  = \"float32\"\n",
        "\n",
        "print(\"Device:\", device)\n",
        "print(\"Dtype:\", dtype)\n",
        "\n",
        "# Clean previous scoring results\n",
        "if output_dir.exists():\n",
        "    shutil.rmtree(output_dir)\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "cmd = (\n",
        "    f\"python scripts/score_sequences.py \"\n",
        "    f\"--checkpoint_dir '{checkpoint_dir}' \"\n",
        "    f\"--conditioning_fasta '{conditioning_fasta}' \"\n",
        "    f\"--candidates_file '{candidates_fasta}' \"\n",
        "    f\"--device {device} \"\n",
        "    f\"--dtype {dtype}\"\n",
        ")\n",
        "\n",
        "print(\"\\nRunning ProFam scoring:\\n\")\n",
        "print(cmd, \"\\n\")\n",
        "\n",
        "!bash -lc \"{cmd}\"\n",
        "\n",
        "print(\"\\nScoring output directory contents:\")\n",
        "!ls -lh \"{output_dir}\""
      ],
      "metadata": {
        "id": "Udql38D3JoVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 21) Inspect ProFam scoring output columns\n",
        "\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "repo = Path(\"/content/profam_workshop/profam\").resolve()\n",
        "scores_path = repo / \"outputs\" / \"candidates_scores.csv\"\n",
        "\n",
        "df_scores = pd.read_csv(scores_path)\n",
        "\n",
        "print(\"Columns in scores file:\")\n",
        "print(df_scores.columns)\n",
        "df_scores.head()"
      ],
      "metadata": {
        "id": "VeA7TWwUOtK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 22) Merge DMS data with ProFam scores\n",
        "\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "repo = Path(\"/content/profam_workshop/profam\").resolve()\n",
        "scores_path = repo / \"outputs\" / \"candidates_scores.csv\"\n",
        "\n",
        "df_scores = pd.read_csv(scores_path)\n",
        "\n",
        "print(\"Scores shape:\", df_scores.shape)\n",
        "\n",
        "# Recreate the SAME capped subset used for FASTA writing\n",
        "df_dms = pd.read_csv(selected_file_path)\n",
        "df_dms = df_dms.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Cap to number actually scored\n",
        "df_dms = df_dms.head(len(df_scores)).copy()\n",
        "\n",
        "# Recreate variant IDs\n",
        "df_dms[\"id\"] = [f\"variant_{i}\" for i in range(len(df_dms))]\n",
        "\n",
        "# Merge\n",
        "df = df_dms.merge(df_scores, on=\"id\")\n",
        "\n",
        "print(\"Merged shape:\", df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "b3XwsLlgOz64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 23) Evaluate ProFam scores against DMS experimental fitness\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import spearmanr\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# df must already exist from the merge cell\n",
        "if \"df\" not in globals():\n",
        "    raise RuntimeError(\"Merged dataframe 'df' not found. Run the merge cell first.\")\n",
        "\n",
        "print(\"Data shape:\", df.shape)\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Spearman correlation (continuous DMS score)\n",
        "# ------------------------------------------------------------------\n",
        "rho, pval = spearmanr(df[\"score\"], df[\"DMS_score\"])\n",
        "\n",
        "print(\"Spearman correlation:\")\n",
        "print(f\"  œÅ = {rho:.4f}\")\n",
        "print(f\"  p-value = {pval:.2e}\")\n",
        "print()\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# AUROC (binary functional classification)\n",
        "# ------------------------------------------------------------------\n",
        "if \"DMS_score_bin\" in df.columns:\n",
        "    auc = roc_auc_score(df[\"DMS_score_bin\"], df[\"score\"])\n",
        "    print(\"AUROC (functional vs non-functional):\")\n",
        "    print(f\"  AUROC = {auc:.4f}\")\n",
        "    print()\n",
        "else:\n",
        "    print(\"No DMS_score_bin column available for AUROC.\\n\")\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Scatter plot\n",
        "# ------------------------------------------------------------------\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.scatter(df[\"DMS_score\"], df[\"score\"], alpha=0.4)\n",
        "plt.xlabel(\"Experimental DMS score\")\n",
        "plt.ylabel(\"ProFam score\")\n",
        "plt.title(f\"ProFam vs DMS (Spearman œÅ = {rho:.2f})\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Optional: Rank-based view\n",
        "# ------------------------------------------------------------------\n",
        "df_sorted = df.sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot(df_sorted[\"DMS_score\"].values)\n",
        "plt.xlabel(\"Variants ranked by ProFam score\")\n",
        "plt.ylabel(\"Experimental DMS score\")\n",
        "plt.title(\"Experimental fitness across ProFam ranking\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UF4H6q44Khmk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}